{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30eadf7a",
   "metadata": {},
   "source": [
    "# data load\n",
    "- {종목명 : 데이터프레임 , ....}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09d6a5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 50개 최적화 파일 로딩 중...\n",
      "✅ AAVE: (1821, 58)\n",
      "✅ ADA: (2879, 58)\n",
      "✅ AETHWETH: (138, 58)\n",
      "✅ ALGO: (2290, 58)\n",
      "✅ AVAX: (1833, 58)\n",
      "✅ BCH: (2879, 58)\n",
      "✅ BGB: (1521, 58)\n",
      "✅ BNB: (2879, 58)\n",
      "✅ BTCB: (2293, 58)\n",
      "✅ BTC: (3922, 58)\n",
      "✅ CBBTC32994: (380, 58)\n",
      "✅ CRO: (2479, 58)\n",
      "✅ DAI: (2136, 58)\n",
      "✅ DOGE: (2879, 58)\n",
      "✅ DOT: (1864, 58)\n",
      "✅ ENA: (543, 58)\n",
      "✅ ETH: (2879, 58)\n",
      "✅ HBAR: (2202, 58)\n",
      "✅ HYPE32196: (302, 58)\n",
      "✅ JITOSOL: (1058, 58)\n",
      "✅ LEO: (2321, 58)\n",
      "✅ LINK: (2879, 58)\n",
      "✅ LTC: (3922, 58)\n",
      "✅ MNT27075: (800, 58)\n",
      "✅ NEAR: (1809, 58)\n",
      "✅ OKB: (2342, 58)\n",
      "✅ PEPE24478: (894, 58)\n",
      "✅ SEI: (771, 58)\n",
      "✅ SHIB: (1842, 58)\n",
      "✅ SOL: (1996, 58)\n",
      "✅ STETH: (1739, 58)\n",
      "✅ SUI20947: (878, 58)\n",
      "✅ SUSDE: (583, 58)\n",
      "✅ TAO22974: (937, 58)\n",
      "✅ TON11419: (1492, 58)\n",
      "✅ TRX: (2879, 58)\n",
      "✅ UNI7083: (1835, 58)\n",
      "✅ USDC: (2546, 58)\n",
      "✅ USDE29470: (585, 58)\n",
      "✅ USDS33039: (373, 58)\n",
      "✅ USDT: (2879, 58)\n",
      "✅ WBETH: (884, 58)\n",
      "✅ WBTC: (2432, 58)\n",
      "✅ WEETH: (654, 58)\n",
      "✅ WETH: (2812, 58)\n",
      "✅ WSTETH: (1451, 58)\n",
      "✅ WTRX: (1302, 58)\n",
      "✅ XLM: (2879, 58)\n",
      "✅ XMR: (2879, 58)\n",
      "✅ XRP: (2879, 58)\n",
      "🎯 로딩 완료: 50개 종목\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_optimized_crypto_data(data_path):\n",
    "    \"\"\"2차 라벨링된 암호화폐 CSV 파일들을 딕셔너리로 로드\"\"\"\n",
    "    \n",
    "    # 최적화된 파일들 찾기\n",
    "    csv_files = glob.glob(os.path.join(data_path, \"*_optimized.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"❌ {data_path}에서 *_optimized.csv 파일을 찾을 수 없습니다.\")\n",
    "        return {}\n",
    "    \n",
    "    processed_stocks = {}\n",
    "    \n",
    "    print(f\"📁 {len(csv_files)}개 최적화 파일 로딩 중...\")\n",
    "    \n",
    "    for file_path in csv_files:\n",
    "        try:\n",
    "            # 심볼명 추출\n",
    "            filename = os.path.basename(file_path)\n",
    "            symbol = filename.replace('_optimized.csv', '')\n",
    "            \n",
    "            # CSV 읽기\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Date 컬럼 처리\n",
    "            if 'Date' in df.columns:\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                df.set_index('Date', inplace=True)\n",
    "            \n",
    "            processed_stocks[symbol] = df\n",
    "            print(f\"✅ {symbol}: {df.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ {filename}: {e}\")\n",
    "    \n",
    "    print(f\"🎯 로딩 완료: {len(processed_stocks)}개 종목\")\n",
    "    return processed_stocks\n",
    "\n",
    "# 사용법\n",
    "data_path = \"/workspace/AI모델/projects/coin/data/v01/optimized\"\n",
    "processed_stocks = load_optimized_crypto_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e930cc",
   "metadata": {},
   "source": [
    "# 피처엔지니어링 정보\n",
    "- Date 제외 : XGBoost는 트리 기반 모델이라 날짜를 숫자로 변환해도 의미있는 패턴을 찾기 어려움\n",
    "- 백테스팅할때만 있으면됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e286efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 학습에서 제외할 컬럼들\n",
    "EXCLUDE_FROM_TRAINING = [\n",
    "    'Date', 'Symbol', 'Future_Label', 'Label', 'Optimized_Label', 'Volatility_Signal', \n",
    "    'Volume_Breakout_Signal', 'Composite_Score',\n",
    "    'Label_Name', 'Optimized_Label_Name', 'Future_Label_Name',\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume',  # 원본 가격/거래량\n",
    "    'Adj Close', 'Dividend', 'Stock Split',  # 기타 원본 데이터\n",
    "]\n",
    "\n",
    "# 백테스팅용 보존 컬럼들\n",
    "BACKTEST_PRESERVE_COLUMNS = [\n",
    "    'Date', 'Open', 'High', 'Low', 'Close', 'Volume', \n",
    "    'Label', 'Label_Name', 'Optimized_Label', 'Optimized_Label_Name', 'Symbol'\n",
    "]\n",
    "\n",
    "# 정규화에서 제외할 Signal/Binary 변수들\n",
    "SIGNAL_FEATURES = [\n",
    "    # 이진 시그널들 (0/1)\n",
    "    'is_month_start', 'is_month_end', 'is_quarter_start', 'is_quarter_end',\n",
    "    # 3단계 시그널들 (0/1/2)\n",
    "    'Formula3_Signal', 'Momentum_Signal',\n",
    "    # 기타 이진 지표들\n",
    "    'high_volatility_regime',\n",
    "    # RSI 관련 이진 지표들\n",
    "    'RSI_7_overbought', 'RSI_7_oversold', 'RSI_14_overbought', 'RSI_14_oversold',\n",
    "    'RSI_30_overbought', 'RSI_30_oversold',\n",
    "    # Stochastic 관련 이진 지표들\n",
    "    'Stoch_1_K_above_D', 'Stoch_3_K_above_D', 'Stoch_4_K_above_D', 'Stoch_5_K_above_D',\n",
    "    'Stoch_6_K_above_D', 'Stoch_14_K_above_D', 'Stoch_1_overbought', 'Stoch_3_overbought',\n",
    "    'Stoch_4_overbought', 'Stoch_5_overbought', 'Stoch_6_overbought', 'Stoch_14_overbought',\n",
    "    'Stoch_1_oversold', 'Stoch_3_oversold', 'Stoch_4_oversold', 'Stoch_5_oversold',\n",
    "    'Stoch_6_oversold', 'Stoch_14_oversold',\n",
    "    # CCI 관련 이진 지표들\n",
    "    'CCI_3_overbought', 'CCI_3_oversold', 'CCI_4_overbought', 'CCI_4_oversold',\n",
    "    'CCI_7_overbought', 'CCI_7_oversold', 'CCI_14_overbought', 'CCI_14_oversold',\n",
    "    # SMI 관련 이진 지표들\n",
    "    'SMI_overbought_40', 'SMI_oversold_40', 'SMI_overbought_50', 'SMI_oversold_50',\n",
    "    # RSI 다이버전스 이진 지표들\n",
    "    'RSI_7_bullish_divergence', 'RSI_7_bearish_divergence', \n",
    "    'RSI_14_bullish_divergence', 'RSI_14_bearish_divergence',\n",
    "    # MACD 관련 이진 지표들\n",
    "    'MACD_7_14_above_signal', 'MACD_14_30_above_signal',\n",
    "    # 원형 인코딩 (이미 정규화됨)\n",
    "    'month_sin', 'month_cos', 'dow_sin', 'dow_cos'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8effca8a",
   "metadata": {},
   "source": [
    "# 전처리 및 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a900fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CryptoXGBoostPreprocessor 클래스 (70:15:15 단순 분할)\n",
    "# =============================================================================\n",
    "\n",
    "class CryptoXGBoostPreprocessor:\n",
    "    \"\"\"암호화폐 XGBoost 전처리기 - 종목별 정규화\"\"\"\n",
    "    \n",
    "    def __init__(self, forecast_horizon=1):\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.symbol_scalers = {}  # 종목별 스케일러 저장\n",
    "        \n",
    "    def prepare_single_crypto(self, df, symbol):\n",
    "        \"\"\"개별 암호화폐 전처리 및 종목별 정규화\"\"\"\n",
    "        df_processed = df.copy()\n",
    "        \n",
    "        print(f\"  처리 중: {symbol} ({df.shape})\")\n",
    "        \n",
    "        # Date 정보 보존 (인덱스에서 컬럼으로)\n",
    "        if 'Date' not in df_processed.columns and isinstance(df_processed.index, pd.DatetimeIndex):\n",
    "            df_processed['Date'] = df_processed.index\n",
    "        \n",
    "        # 1. Future_Label 생성\n",
    "        if 'Future_Label' not in df_processed.columns:\n",
    "            if 'Optimized_Label' in df_processed.columns:\n",
    "                df_processed['Future_Label'] = df_processed['Optimized_Label'].shift(-self.forecast_horizon)\n",
    "            else:\n",
    "                print(f\"    Warning: {symbol}에 Optimized_Label 없음\")\n",
    "                return None\n",
    "        \n",
    "        # 2. 심볼 정보 추가\n",
    "        df_processed['Symbol'] = symbol\n",
    "        \n",
    "        # 3. 무한값 및 극값 처리\n",
    "        numeric_cols = df_processed.select_dtypes(include=[np.number]).columns\n",
    "        df_processed[numeric_cols] = df_processed[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
    "        \n",
    "        # 극값 클리핑 (종목별로)\n",
    "        for col in numeric_cols:\n",
    "            if df_processed[col].notna().sum() > 0:\n",
    "                p99 = df_processed[col].quantile(0.999)\n",
    "                p01 = df_processed[col].quantile(0.001)\n",
    "                if not pd.isna(p99) and not pd.isna(p01):\n",
    "                    df_processed[col] = df_processed[col].clip(lower=p01, upper=p99)\n",
    "        \n",
    "        # 4. NaN 채우기\n",
    "        df_processed[numeric_cols] = df_processed[numeric_cols].fillna(0)\n",
    "        \n",
    "        # 5. 종목별 정규화 적용\n",
    "        df_normalized = self.apply_symbol_scaling(df_processed, symbol)\n",
    "        \n",
    "        # 6. Future_Label이 있는 데이터만 유지\n",
    "        df_final = df_normalized.dropna(subset=['Future_Label']).copy()\n",
    "        \n",
    "        print(f\"    완료: {df_final.shape}, 라벨수={df_final['Future_Label'].nunique()}\")\n",
    "        \n",
    "        return df_final\n",
    "    \n",
    "    def apply_symbol_scaling(self, df, symbol):\n",
    "        \"\"\"종목별 스케일링 적용\"\"\"\n",
    "        df_scaled = df.copy()\n",
    "        \n",
    "        # 스케일링 제외 컬럼들\n",
    "        exclude_cols = set(EXCLUDE_FROM_TRAINING + SIGNAL_FEATURES + ['year', 'month', 'quarter', 'day_of_week'])\n",
    "        string_cols = set(df_scaled.select_dtypes(include=['object']).columns)\n",
    "        all_exclude = exclude_cols | string_cols\n",
    "        \n",
    "        # 스케일링 대상 피쳐\n",
    "        scale_features = [col for col in df_scaled.columns if col not in all_exclude]\n",
    "        \n",
    "        if scale_features:\n",
    "            # 종목별 스케일러 생성/사용\n",
    "            if symbol not in self.symbol_scalers:\n",
    "                self.symbol_scalers[symbol] = StandardScaler()\n",
    "            \n",
    "            try:\n",
    "                df_scaled[scale_features] = self.symbol_scalers[symbol].fit_transform(df_scaled[scale_features])\n",
    "            except Exception as e:\n",
    "                print(f\"    스케일링 실패 ({symbol}): {e}\")\n",
    "                df_scaled[scale_features] = 0\n",
    "        \n",
    "        return df_scaled\n",
    "    \n",
    "    def split_symbol_data(self, df, train_ratio=0.7, val_ratio=0.15):\n",
    "        \"\"\"종목별 시계열 데이터 분할 - 70:15:15\"\"\"\n",
    "        n = len(df)\n",
    "        train_end = int(n * train_ratio)\n",
    "        val_end = int(n * (train_ratio + val_ratio))\n",
    "        \n",
    "        train_data = df.iloc[:train_end].copy()\n",
    "        val_data = df.iloc[train_end:val_end].copy()\n",
    "        test_data = df.iloc[val_end:].copy()\n",
    "        \n",
    "        return train_data, val_data, test_data\n",
    "    \n",
    "    def process_all_cryptos(self, crypto_data, output_dir):\n",
    "        \"\"\"전체 암호화폐 처리 - 종목별 분할\"\"\"\n",
    "        print(\"암호화폐 XGBoost 전처리 시작 (종목별 정규화)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # 결과 저장용\n",
    "        all_train_data = []\n",
    "        all_val_data = []\n",
    "        all_test_data = []\n",
    "        backtest_data = {}  # 백테스팅용 원본 데이터\n",
    "        symbol_stats = {}\n",
    "        \n",
    "        for symbol, df in crypto_data.items():\n",
    "            try:\n",
    "                # 1. 백테스팅용 원본 데이터 보존 (전체 기간)\n",
    "                df_reset = df.reset_index()\n",
    "                if 'Date' not in df_reset.columns and isinstance(df.index, pd.DatetimeIndex):\n",
    "                    df_reset['Date'] = df.index\n",
    "                \n",
    "                available_cols = [col for col in BACKTEST_PRESERVE_COLUMNS if col in df_reset.columns]\n",
    "                backtest_data[symbol] = df_reset[available_cols].copy()\n",
    "                \n",
    "                # 2. 전처리 및 종목별 정규화\n",
    "                processed_df = self.prepare_single_crypto(df, symbol)\n",
    "                \n",
    "                if processed_df is None or len(processed_df) < 30:\n",
    "                    print(f\"    스킵: {symbol} (데이터 부족)\")\n",
    "                    continue\n",
    "                \n",
    "                # 3. 종목별 시계열 분할 (70:15:15)\n",
    "                train_data, val_data, test_data = self.split_symbol_data(processed_df)\n",
    "                \n",
    "                # 4. 각 세트에 데이터 추가\n",
    "                if len(train_data) > 0:\n",
    "                    all_train_data.append(train_data)\n",
    "                if len(val_data) > 0:\n",
    "                    all_val_data.append(val_data)\n",
    "                if len(test_data) > 0:\n",
    "                    all_test_data.append(test_data)\n",
    "                \n",
    "                # 5. 종목별 통계 저장\n",
    "                symbol_stats[symbol] = {\n",
    "                    'total_rows': len(processed_df),\n",
    "                    'train_rows': len(train_data),\n",
    "                    'val_rows': len(val_data),\n",
    "                    'test_rows': len(test_data),\n",
    "                    'label_dist': processed_df['Future_Label'].value_counts().to_dict()\n",
    "                }\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    오류: {symbol} - {e}\")\n",
    "                continue\n",
    "        \n",
    "        # 6. 데이터 결합\n",
    "        if not all_train_data:\n",
    "            raise ValueError(\"처리된 데이터가 없습니다!\")\n",
    "        \n",
    "        train_df = pd.concat(all_train_data, axis=0, ignore_index=True)\n",
    "        val_df = pd.concat(all_val_data, axis=0, ignore_index=True) if all_val_data else pd.DataFrame()\n",
    "        test_df = pd.concat(all_test_data, axis=0, ignore_index=True) if all_test_data else pd.DataFrame()\n",
    "        \n",
    "        print(f\"\\n종목별 분할 후 전체 데이터:\")\n",
    "        print(f\"  훈련: {len(train_df):,}개 (70%)\")\n",
    "        print(f\"  검증: {len(val_df):,}개 (15%)\") \n",
    "        print(f\"  테스트: {len(test_df):,}개 (15%)\")\n",
    "        \n",
    "        # 7. 종목별 통계 출력\n",
    "        print(f\"\\n종목별 데이터 분포:\")\n",
    "        for symbol, stats in symbol_stats.items():\n",
    "            print(f\"  {symbol}: train={stats['train_rows']}, val={stats['val_rows']}, test={stats['test_rows']}\")\n",
    "        \n",
    "        # 8. 전체 라벨 분포\n",
    "        if len(train_df) > 0:\n",
    "            print(f\"\\n전체 라벨 분포:\")\n",
    "            for dataset_name, dataset in [('Train', train_df), ('Val', val_df), ('Test', test_df)]:\n",
    "                if len(dataset) > 0:\n",
    "                    label_counts = dataset['Future_Label'].value_counts().sort_index()\n",
    "                    print(f\"  {dataset_name}:\")\n",
    "                    for label, count in label_counts.items():\n",
    "                        label_name = {0: 'Sell', 1: 'Hold', 2: 'Buy'}[int(label)]\n",
    "                        print(f\"    {int(label)} ({label_name}): {count:,}개\")\n",
    "        \n",
    "        # 9. 학습용 피쳐 선택\n",
    "        training_features = [col for col in train_df.columns if col not in EXCLUDE_FROM_TRAINING]\n",
    "        print(f\"\\n학습용 피쳐: {len(training_features)}개\")\n",
    "        \n",
    "        # 10. 데이터 저장\n",
    "        self.save_processed_data(train_df, val_df, test_df, backtest_data, \n",
    "                               training_features, symbol_stats, output_dir)\n",
    "        \n",
    "        return train_df, val_df, test_df, backtest_data, training_features\n",
    "    \n",
    "    def save_processed_data(self, train_df, val_df, test_df, backtest_data, \n",
    "                          training_features, symbol_stats, output_dir):\n",
    "        \"\"\"처리된 데이터 저장\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 학습용 데이터 저장\n",
    "        train_df.to_csv(os.path.join(output_dir, 'train_data.csv'), index=False)\n",
    "        if len(val_df) > 0:\n",
    "            val_df.to_csv(os.path.join(output_dir, 'val_data.csv'), index=False)\n",
    "        if len(test_df) > 0:\n",
    "            test_df.to_csv(os.path.join(output_dir, 'test_data.csv'), index=False)\n",
    "        \n",
    "        # 전체 학습 데이터 (train + val + test)\n",
    "        all_data = pd.concat([train_df, val_df, test_df], axis=0, ignore_index=True)\n",
    "        all_data.to_csv(os.path.join(output_dir, 'xgboost_training_data.csv'), index=False)\n",
    "        \n",
    "        # 백테스팅 원본 데이터 저장\n",
    "        backtest_dir = os.path.join(output_dir, 'backtest_data')\n",
    "        os.makedirs(backtest_dir, exist_ok=True)\n",
    "        for symbol, data in backtest_data.items():\n",
    "            data.to_csv(os.path.join(backtest_dir, f'{symbol}_backtest.csv'), index=False)\n",
    "        \n",
    "        # 전처리기 및 메타데이터\n",
    "        joblib.dump(self, os.path.join(output_dir, 'crypto_xgboost_preprocessor.pkl'))\n",
    "        \n",
    "        with open(os.path.join(output_dir, 'training_features.txt'), 'w') as f:\n",
    "            for feature in training_features:\n",
    "                f.write(f\"{feature}\\n\")\n",
    "        \n",
    "        # 종목별 통계\n",
    "        import json\n",
    "        with open(os.path.join(output_dir, 'symbol_stats.json'), 'w') as f:\n",
    "            json.dump(symbol_stats, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n데이터 분할 완료:\")\n",
    "        print(f\"   훈련: 70%\")\n",
    "        print(f\"   검증: 15%\") \n",
    "        print(f\"   테스트: 15%\")\n",
    "        print(f\"\\n저장 완료: {output_dir}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# prepare_xgboost_data 함수 (70:15:15 단순 분할)\n",
    "# =============================================================================\n",
    "\n",
    "def prepare_xgboost_data(processed_stocks, output_dir='./data/xgboost', \n",
    "                        forecast_horizon=1, target_symbols=None):\n",
    "    \"\"\"\n",
    "    암호화폐 XGBoost 데이터 전처리 메인 함수 (70:15:15 분할)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"암호화폐 XGBoost 전처리 시작\")\n",
    "    print(f\"예측 기간: {forecast_horizon}일\")\n",
    "    print(f\"종목별 정규화 적용\")\n",
    "    \n",
    "    # 타겟 심볼 필터링\n",
    "    if target_symbols is not None:\n",
    "        filtered_stocks = {}\n",
    "        for target in target_symbols:\n",
    "            clean_target = target.replace('-USD', '').replace('_USDT', '')\n",
    "            for symbol in processed_stocks.keys():\n",
    "                clean_symbol = symbol.replace('-USD', '').replace('_USDT', '')\n",
    "                if clean_symbol == clean_target:\n",
    "                    filtered_stocks[symbol] = processed_stocks[symbol]\n",
    "                    break\n",
    "        processed_stocks = filtered_stocks\n",
    "        print(f\"필터링된 종목: {list(processed_stocks.keys())}\")\n",
    "    \n",
    "    if not processed_stocks:\n",
    "        raise ValueError(\"선택된 종목이 없습니다!\")\n",
    "    \n",
    "    # 전처리기 실행\n",
    "    preprocessor = CryptoXGBoostPreprocessor(forecast_horizon=forecast_horizon)\n",
    "    train_df, val_df, test_df, backtest_data, training_features = preprocessor.process_all_cryptos(\n",
    "        processed_stocks, output_dir\n",
    "    )\n",
    "    \n",
    "    print(\"모든 전처리 완료!\")\n",
    "    \n",
    "    return {\n",
    "        'train': train_df,\n",
    "        'val': val_df, \n",
    "        'test': test_df,\n",
    "        'backtest_data': backtest_data,\n",
    "        'training_features': training_features,\n",
    "        'preprocessor': preprocessor\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebc5b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/workspace/AI모델/projects/coin/data/v01/crypto_xgboost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdfea94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 50개 최적화 파일 로딩 중...\n",
      "✅ AAVE: (1821, 58)\n",
      "✅ ADA: (2879, 58)\n",
      "✅ AETHWETH: (138, 58)\n",
      "✅ ALGO: (2290, 58)\n",
      "✅ AVAX: (1833, 58)\n",
      "✅ BCH: (2879, 58)\n",
      "✅ BGB: (1521, 58)\n",
      "✅ BNB: (2879, 58)\n",
      "✅ BTCB: (2293, 58)\n",
      "✅ BTC: (3922, 58)\n",
      "✅ CBBTC32994: (380, 58)\n",
      "✅ CRO: (2479, 58)\n",
      "✅ DAI: (2136, 58)\n",
      "✅ DOGE: (2879, 58)\n",
      "✅ DOT: (1864, 58)\n",
      "✅ ENA: (543, 58)\n",
      "✅ ETH: (2879, 58)\n",
      "✅ HBAR: (2202, 58)\n",
      "✅ HYPE32196: (302, 58)\n",
      "✅ JITOSOL: (1058, 58)\n",
      "✅ LEO: (2321, 58)\n",
      "✅ LINK: (2879, 58)\n",
      "✅ LTC: (3922, 58)\n",
      "✅ MNT27075: (800, 58)\n",
      "✅ NEAR: (1809, 58)\n",
      "✅ OKB: (2342, 58)\n",
      "✅ PEPE24478: (894, 58)\n",
      "✅ SEI: (771, 58)\n",
      "✅ SHIB: (1842, 58)\n",
      "✅ SOL: (1996, 58)\n",
      "✅ STETH: (1739, 58)\n",
      "✅ SUI20947: (878, 58)\n",
      "✅ SUSDE: (583, 58)\n",
      "✅ TAO22974: (937, 58)\n",
      "✅ TON11419: (1492, 58)\n",
      "✅ TRX: (2879, 58)\n",
      "✅ UNI7083: (1835, 58)\n",
      "✅ USDC: (2546, 58)\n",
      "✅ USDE29470: (585, 58)\n",
      "✅ USDS33039: (373, 58)\n",
      "✅ USDT: (2879, 58)\n",
      "✅ WBETH: (884, 58)\n",
      "✅ WBTC: (2432, 58)\n",
      "✅ WEETH: (654, 58)\n",
      "✅ WETH: (2812, 58)\n",
      "✅ WSTETH: (1451, 58)\n",
      "✅ WTRX: (1302, 58)\n",
      "✅ XLM: (2879, 58)\n",
      "✅ XMR: (2879, 58)\n",
      "✅ XRP: (2879, 58)\n",
      "🎯 로딩 완료: 50개 종목\n",
      "암호화폐 XGBoost 전처리 시작\n",
      "예측 기간: 1일\n",
      "종목별 정규화 적용\n",
      "암호화폐 XGBoost 전처리 시작 (종목별 정규화)\n",
      "============================================================\n",
      "  처리 중: AAVE ((1821, 58))\n",
      "    완료: (1821, 60), 라벨수=3\n",
      "  처리 중: ADA ((2879, 58))\n",
      "    완료: (2879, 60), 라벨수=3\n",
      "  처리 중: AETHWETH ((138, 58))\n",
      "    완료: (138, 60), 라벨수=3\n",
      "  처리 중: ALGO ((2290, 58))\n",
      "    완료: (2290, 60), 라벨수=3\n",
      "  처리 중: AVAX ((1833, 58))\n",
      "    완료: (1833, 60), 라벨수=3\n",
      "  처리 중: BCH ((2879, 58))\n",
      "    완료: (2879, 60), 라벨수=3\n",
      "  처리 중: BGB ((1521, 58))\n",
      "    완료: (1521, 60), 라벨수=3\n",
      "  처리 중: BNB ((2879, 58))\n",
      "    완료: (2879, 60), 라벨수=3\n",
      "  처리 중: BTCB ((2293, 58))\n",
      "    완료: (2293, 60), 라벨수=3\n",
      "  처리 중: BTC ((3922, 58))\n",
      "    완료: (3922, 60), 라벨수=3\n",
      "  처리 중: CBBTC32994 ((380, 58))\n",
      "    완료: (380, 60), 라벨수=3\n",
      "  처리 중: CRO ((2479, 58))\n",
      "    완료: (2479, 60), 라벨수=3\n",
      "  처리 중: DAI ((2136, 58))\n",
      "    완료: (2136, 60), 라벨수=3\n",
      "  처리 중: DOGE ((2879, 58))\n",
      "    완료: (2879, 60), 라벨수=3\n",
      "  처리 중: DOT ((1864, 58))\n",
      "    완료: (1864, 60), 라벨수=3\n",
      "  처리 중: ENA ((543, 58))\n",
      "    완료: (543, 60), 라벨수=3\n",
      "  처리 중: ETH ((2879, 58))\n",
      "    완료: (2879, 60), 라벨수=3\n",
      "  처리 중: HBAR ((2202, 58))\n",
      "    완료: (2202, 60), 라벨수=3\n",
      "  처리 중: HYPE32196 ((302, 58))\n",
      "    완료: (302, 60), 라벨수=3\n",
      "  처리 중: JITOSOL ((1058, 58))\n",
      "    완료: (1058, 60), 라벨수=3\n",
      "  처리 중: LEO ((2321, 58))\n",
      "    완료: (2321, 60), 라벨수=3\n",
      "  처리 중: LINK ((2879, 58))\n",
      "    완료: (2879, 60), 라벨수=3\n",
      "  처리 중: LTC ((3922, 58))\n",
      "    완료: (3922, 60), 라벨수=3\n",
      "  처리 중: MNT27075 ((800, 58))\n",
      "    완료: (800, 60), 라벨수=3\n",
      "  처리 중: NEAR ((1809, 58))\n",
      "    완료: (1809, 60), 라벨수=3\n",
      "  처리 중: OKB ((2342, 58))\n",
      "    완료: (2342, 60), 라벨수=3\n",
      "  처리 중: PEPE24478 ((894, 58))\n",
      "    완료: (894, 60), 라벨수=3\n",
      "  처리 중: SEI ((771, 58))\n",
      "    완료: (771, 60), 라벨수=3\n",
      "  처리 중: SHIB ((1842, 58))\n",
      "    완료: (1842, 60), 라벨수=3\n",
      "  처리 중: SOL ((1996, 58))\n",
      "    완료: (1996, 60), 라벨수=3\n",
      "  처리 중: STETH ((1739, 58))\n",
      "    완료: (1739, 60), 라벨수=3\n",
      "  처리 중: SUI20947 ((878, 58))\n",
      "    완료: (878, 60), 라벨수=3\n",
      "  처리 중: SUSDE ((583, 58))\n",
      "    완료: (583, 60), 라벨수=1\n",
      "  처리 중: TAO22974 ((937, 58))\n",
      "    완료: (937, 60), 라벨수=3\n",
      "  처리 중: TON11419 ((1492, 58))\n",
      "    완료: (1492, 60), 라벨수=3\n",
      "  처리 중: TRX ((2879, 58))\n",
      "    완료: (2879, 60), 라벨수=3\n",
      "  처리 중: UNI7083 ((1835, 58))\n",
      "    완료: (1835, 60), 라벨수=3\n",
      "  처리 중: USDC ((2546, 58))\n",
      "    완료: (2546, 60), 라벨수=2\n",
      "  처리 중: USDE29470 ((585, 58))\n",
      "    완료: (585, 60), 라벨수=1\n",
      "  처리 중: USDS33039 ((373, 58))\n",
      "    완료: (373, 60), 라벨수=3\n",
      "  처리 중: USDT ((2879, 58))\n",
      "    완료: (2879, 60), 라벨수=3\n",
      "  처리 중: WBETH ((884, 58))\n",
      "    완료: (884, 60), 라벨수=3\n",
      "  처리 중: WBTC ((2432, 58))\n",
      "    완료: (2432, 60), 라벨수=3\n",
      "  처리 중: WEETH ((654, 58))\n",
      "    완료: (654, 60), 라벨수=3\n",
      "  처리 중: WETH ((2812, 58))\n",
      "    완료: (2812, 60), 라벨수=3\n",
      "  처리 중: WSTETH ((1451, 58))\n",
      "    완료: (1451, 60), 라벨수=3\n",
      "  처리 중: WTRX ((1302, 58))\n",
      "    완료: (1302, 60), 라벨수=3\n",
      "  처리 중: XLM ((2879, 58))\n",
      "    완료: (2879, 60), 라벨수=3\n",
      "  처리 중: XMR ((2879, 58))\n",
      "    완료: (2879, 60), 라벨수=3\n",
      "  처리 중: XRP ((2879, 58))\n",
      "    완료: (2879, 60), 라벨수=3\n",
      "\n",
      "종목별 분할 후 전체 데이터:\n",
      "  훈련: 65,536개 (70%)\n",
      "  검증: 14,048개 (15%)\n",
      "  테스트: 14,067개 (15%)\n",
      "\n",
      "종목별 데이터 분포:\n",
      "  AAVE: train=1274, val=273, test=274\n",
      "  ADA: train=2015, val=432, test=432\n",
      "  AETHWETH: train=96, val=21, test=21\n",
      "  ALGO: train=1603, val=343, test=344\n",
      "  AVAX: train=1283, val=275, test=275\n",
      "  BCH: train=2015, val=432, test=432\n",
      "  BGB: train=1064, val=228, test=229\n",
      "  BNB: train=2015, val=432, test=432\n",
      "  BTCB: train=1605, val=344, test=344\n",
      "  BTC: train=2745, val=588, test=589\n",
      "  CBBTC32994: train=266, val=57, test=57\n",
      "  CRO: train=1735, val=372, test=372\n",
      "  DAI: train=1495, val=320, test=321\n",
      "  DOGE: train=2015, val=432, test=432\n",
      "  DOT: train=1304, val=280, test=280\n",
      "  ENA: train=380, val=81, test=82\n",
      "  ETH: train=2015, val=432, test=432\n",
      "  HBAR: train=1541, val=330, test=331\n",
      "  HYPE32196: train=211, val=45, test=46\n",
      "  JITOSOL: train=740, val=159, test=159\n",
      "  LEO: train=1624, val=348, test=349\n",
      "  LINK: train=2015, val=432, test=432\n",
      "  LTC: train=2745, val=588, test=589\n",
      "  MNT27075: train=560, val=120, test=120\n",
      "  NEAR: train=1266, val=271, test=272\n",
      "  OKB: train=1639, val=351, test=352\n",
      "  PEPE24478: train=625, val=134, test=135\n",
      "  SEI: train=539, val=116, test=116\n",
      "  SHIB: train=1289, val=276, test=277\n",
      "  SOL: train=1397, val=299, test=300\n",
      "  STETH: train=1217, val=261, test=261\n",
      "  SUI20947: train=614, val=132, test=132\n",
      "  SUSDE: train=408, val=87, test=88\n",
      "  TAO22974: train=655, val=141, test=141\n",
      "  TON11419: train=1044, val=224, test=224\n",
      "  TRX: train=2015, val=432, test=432\n",
      "  UNI7083: train=1284, val=275, test=276\n",
      "  USDC: train=1782, val=382, test=382\n",
      "  USDE29470: train=409, val=88, test=88\n",
      "  USDS33039: train=261, val=56, test=56\n",
      "  USDT: train=2015, val=432, test=432\n",
      "  WBETH: train=618, val=133, test=133\n",
      "  WBTC: train=1702, val=365, test=365\n",
      "  WEETH: train=457, val=98, test=99\n",
      "  WETH: train=1968, val=422, test=422\n",
      "  WSTETH: train=1015, val=218, test=218\n",
      "  WTRX: train=911, val=195, test=196\n",
      "  XLM: train=2015, val=432, test=432\n",
      "  XMR: train=2015, val=432, test=432\n",
      "  XRP: train=2015, val=432, test=432\n",
      "\n",
      "전체 라벨 분포:\n",
      "  Train:\n",
      "    0 (Sell): 8,394개\n",
      "    0 (Sell): 3개\n",
      "    1 (Hold): 48,713개\n",
      "    1 (Hold): 3개\n",
      "    2 (Buy): 8,423개\n",
      "  Val:\n",
      "    0 (Sell): 1,503개\n",
      "    1 (Hold): 11,052개\n",
      "    2 (Buy): 1,493개\n",
      "  Test:\n",
      "    0 (Sell): 1,580개\n",
      "    1 (Hold): 10,891개\n",
      "    2 (Buy): 1,596개\n",
      "\n",
      "학습용 피쳐: 46개\n",
      "\n",
      "데이터 분할 완료:\n",
      "   훈련: 70%\n",
      "   검증: 15%\n",
      "   테스트: 15%\n",
      "\n",
      "저장 완료: /workspace/AI모델/projects/coin/data/v01/crypto_xgboost\n",
      "모든 전처리 완료!\n",
      "\n",
      "최종 결과:\n",
      "훈련 데이터: (65536, 60)\n",
      "검증 데이터: (14048, 60)\n",
      "테스트 데이터: (14067, 60)\n",
      "백테스팅 데이터: 50개 종목\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. 실행 부분 (기존과 동일)\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. 데이터 로드\n",
    "    data_path = \"/workspace/AI모델/projects/coin/data/v01/optimized\"\n",
    "    processed_stocks = load_optimized_crypto_data(data_path)\n",
    "    \n",
    "    # 2. 전처리\n",
    "    result = prepare_xgboost_data(\n",
    "        processed_stocks=processed_stocks,\n",
    "        output_dir=output_dir,\n",
    "        forecast_horizon=1,\n",
    "        target_symbols=None  # 전체 종목\n",
    "    )\n",
    "    \n",
    "    # 3. 결과 확인\n",
    "    print(f\"\\n최종 결과:\")\n",
    "    print(f\"훈련 데이터: {result['train'].shape}\")\n",
    "    print(f\"검증 데이터: {result['val'].shape}\")\n",
    "    print(f\"테스트 데이터: {result['test'].shape}\")\n",
    "    print(f\"백테스팅 데이터: {len(result['backtest_data'])}개 종목\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e44eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
