{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4069308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필수 라이브러리 로드 완료\n",
      "XGBoost 버전: 3.0.4\n",
      "Optuna 버전: 4.5.0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 셀 1: 라이브러리 및 초기 설정\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 머신러닝 라이브러리\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 메모리 관리\n",
    "import gc\n",
    "import psutil\n",
    "import subprocess\n",
    "\n",
    "print(\"필수 라이브러리 로드 완료\")\n",
    "print(f\"XGBoost 버전: {xgb.__version__}\")\n",
    "print(f\"Optuna 버전: {optuna.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "011a8852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 디렉토리: /workspace/AI모델/projects/coin/data/v01/crypto_xgboost\n",
      "출력 디렉토리: /workspace/AI모델/projects/coin/models/v01/crypto_xgboost\n",
      "K-Fold: 5폴드, Optuna 시도: 20회\n",
      "GPU 사용: True\n",
      "시스템 RAM: 47.0GB (사용가능: 38.4GB)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 셀 2: 경로 설정 및 디렉토리 생성\n",
    "# =============================================================================\n",
    "\n",
    "# 경로 설정\n",
    "data_dir = \"/workspace/AI모델/projects/coin/data/v01/crypto_xgboost\"  # 전처리된 데이터 경로\n",
    "output_dir = \"/workspace/AI모델/projects/coin/models/v01/crypto_xgboost\"  # 모델 저장 경로\n",
    "\n",
    "# 디렉토리 생성\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 설정값\n",
    "N_FOLDS = 5     \n",
    "N_TRIALS = 20   # 20번 시도 (암호화폐는 더 많은 시도 필요)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# GPU 최적화 설정\n",
    "USE_GPU = True\n",
    "GPU_DEVICE = 'cuda:0'\n",
    "GPU_BATCH_SIZE = 10000\n",
    "PARALLEL_JOBS = 1      # GPU 사용시에는 1 또는 2가 최적\n",
    "\n",
    "# 메모리 모니터링 활성화\n",
    "MEMORY_MONITORING = True\n",
    "\n",
    "print(f\"데이터 디렉토리: {data_dir}\")\n",
    "print(f\"출력 디렉토리: {output_dir}\")\n",
    "print(f\"K-Fold: {N_FOLDS}폴드, Optuna 시도: {N_TRIALS}회\")\n",
    "print(f\"GPU 사용: {USE_GPU}\")\n",
    "\n",
    "# 시스템 메모리 확인\n",
    "total_ram = psutil.virtual_memory().total / (1024**3)\n",
    "available_ram = psutil.virtual_memory().available / (1024**3)\n",
    "print(f\"시스템 RAM: {total_ram:.1f}GB (사용가능: {available_ram:.1f}GB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb787df",
   "metadata": {},
   "source": [
    "# 피처엔지니어링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "38caaed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "암호화폐 데이터 로드 시작...\n",
      "training_features.txt에서 46개 기본 피처 로드\n",
      "데이터 로드 완료:\n",
      "  훈련: (65536, 60)\n",
      "  검증: (14048, 60)\n",
      "  테스트: (14067, 60)\n",
      "training_features.txt 기반 피처: 46개\n",
      "피처 제외 항목: 37개\n",
      "최종 피쳐 수: 28\n",
      "데이터 전처리 완료:\n",
      "  X_train_val: (79584, 28)\n",
      "  X_test: (14067, 28)\n",
      "클래스 분포:\n",
      "  훈련+검증:\n",
      "    0 (Strong_Sell): 9,897개 (12.4%)\n",
      "    0 (Strong_Sell): 3개 (0.0%)\n",
      "    1 (Hold): 59,765개 (75.1%)\n",
      "    1 (Hold): 3개 (0.0%)\n",
      "    2 (Strong_Buy): 9,916개 (12.5%)\n",
      "  테스트:\n",
      "    0 (Strong_Sell): 1,580개 (11.2%)\n",
      "    1 (Hold): 10,891개 (77.4%)\n",
      "    2 (Strong_Buy): 1,596개 (11.3%)\n",
      "클래스 균형도: 0.000 (1.0에 가까울수록 균형)\n",
      "데이터 검증:\n",
      "  결측치 - X_train_val: 0\n",
      "  결측치 - X_test: 0\n",
      "  무한값 - X_train_val: 0\n",
      "  무한값 - X_test: 0\n",
      "데이터 준비 완료!\n",
      "사용할 피쳐 수: 28\n",
      "주요 피쳐들:\n",
      "   1. Stoch_14_K_above_D\n",
      "   2. Stoch_6_K_above_D\n",
      "   3. CCI_4_overbought\n",
      "   4. Formula3_Signal\n",
      "   5. Stoch_1_K_above_D\n",
      "   6. Stoch_4_K_above_D\n",
      "   7. is_quarter_start\n",
      "   8. high_volatility_regime\n",
      "   9. is_month_end\n",
      "  10. Stoch_3_K_above_D\n",
      "  11. Stoch_K_3\n",
      "  12. is_month_start\n",
      "  13. Momentum_Signal\n",
      "  14. day_of_week\n",
      "  15. Volatility_7d\n",
      "  ... 외 13개\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 셀 3: 데이터 로드 및 전처리\n",
    "# =============================================================================\n",
    "\n",
    "def load_and_prepare_crypto_data(data_dir):\n",
    "    \"\"\"암호화폐 데이터 로드 및 전처리\"\"\"\n",
    "    print(\"암호화폐 데이터 로드 시작...\")\n",
    "    \n",
    "    # 1. training_features.txt 파일 읽기\n",
    "    feature_file = os.path.join(data_dir, 'training_features.txt')\n",
    "    \n",
    "    if os.path.exists(feature_file):\n",
    "        with open(feature_file, 'r') as f:\n",
    "            base_features = [line.strip() for line in f.readlines() if line.strip()]\n",
    "        print(f\"training_features.txt에서 {len(base_features)}개 기본 피처 로드\")\n",
    "    else:\n",
    "        print(f\"⚠️ training_features.txt 파일이 없습니다: {feature_file}\")\n",
    "        base_features = None\n",
    "    \n",
    "    # 2. 데이터 로드\n",
    "    train_df = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))\n",
    "    val_df = pd.read_csv(os.path.join(data_dir, 'val_data.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(data_dir, 'test_data.csv'))\n",
    "    \n",
    "    print(f\"데이터 로드 완료:\")\n",
    "    print(f\"  훈련: {train_df.shape}\")\n",
    "    print(f\"  검증: {val_df.shape}\")\n",
    "    print(f\"  테스트: {test_df.shape}\")\n",
    "        \n",
    "    # 3. 암호화폐 특성에 맞는 추가 제외 피처들\n",
    "    crypto_exclude = [\n",
    "        # 원본 OHLCV 데이터\n",
    "        'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "        \n",
    "        # 라벨 관련\n",
    "        'Future_Label', 'Label', 'Optimized_Label', 'Future_Label_Name',\n",
    "        'Label_Name', 'Optimized_Label_Name',\n",
    "        \n",
    "        # 데이터 누수 방지 - 모든 Future 관련 컬럼들\n",
    "        'Future_Return_1d', 'Future_Return_3d', 'Future_Return_7d', \n",
    "        'Future_Return_14d', 'Future_Return_30d', 'Future_Return_90d',\n",
    "        'Future_Label_1d', 'Future_Label_3d', 'Future_Label_7d',\n",
    "        'Future_Label_14d', 'Future_Label_30d', 'Future_Label_90d',\n",
    "        'Technical_Score', 'Final_Score',\n",
    "\n",
    "\n",
    "        # 메타 데이터\n",
    "        'Date', 'Symbol',\n",
    "        \n",
    "        # 완전 중복 지표들 (상관계수 1.0)\n",
    "        'SMI_ema', 'SMI', 'SMI_normalized', # SMI_Signal와 높은 상관관계\n",
    "        \n",
    "        # 높은 상관관계 피처들 (암호화폐 특성상 제거)\n",
    "        'MACD_7_14_signal_distance', 'MACD_14_30_signal_distance',\n",
    "        \n",
    "        # VIF가 높은 피처들\n",
    "        'realized_volatility_5', 'realized_volatility_20',\n",
    "        \n",
    "        # 시간 관련 중복\n",
    "        'quarter', 'dow_cos',  # 다른 시간 피처로 충분히 표현됨\n",
    "        \n",
    "        # 암호화폐에서 효과가 낮은 지표들\n",
    "        'year',  # 암호화폐는 짧은 역사로 year 피처 의미 제한적\n",
    "    ]\n",
    "    \n",
    "    # 4. 최종 피쳐 결정\n",
    "    if base_features is not None:\n",
    "        # training_features.txt에서 제외 항목을 빼기\n",
    "        feature_columns = [f for f in base_features if f not in crypto_exclude]\n",
    "        print(f\"training_features.txt 기반 피처: {len(base_features)}개\")\n",
    "        print(f\"피처 제외 항목: {len(crypto_exclude)}개\")\n",
    "    else:\n",
    "        # training_features.txt가 없으면 전체 컬럼에서 제외\n",
    "        feature_columns = [col for col in train_df.columns if col not in crypto_exclude]\n",
    "    \n",
    "    # 5. 실제 존재하는 피쳐만 필터링\n",
    "    feature_columns = [col for col in feature_columns if col in train_df.columns]\n",
    "    \n",
    "    # Future_Label 제거 (타겟이므로)\n",
    "    if 'Future_Label' in feature_columns:\n",
    "        feature_columns.remove('Future_Label')\n",
    "    \n",
    "    print(f\"최종 피쳐 수: {len(feature_columns)}\")\n",
    "    \n",
    "    # 6. Future_Label 확인\n",
    "    if 'Future_Label' not in train_df.columns:\n",
    "        raise ValueError(\"Future_Label 컬럼이 없습니다!\")\n",
    "    \n",
    "    # 7. 훈련+검증 데이터 합치기\n",
    "    train_val_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "    \n",
    "    # 8. 피쳐와 타겟 분리\n",
    "    X_train_val = train_val_df[feature_columns].fillna(0)\n",
    "    y_train_val = train_val_df['Future_Label']\n",
    "    \n",
    "    X_test = test_df[feature_columns].fillna(0)\n",
    "    y_test = test_df['Future_Label']\n",
    "    \n",
    "    # 9. 무한값 처리\n",
    "    X_train_val = X_train_val.replace([np.inf, -np.inf], 0)\n",
    "    X_test = X_test.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    print(f\"데이터 전처리 완료:\")\n",
    "    print(f\"  X_train_val: {X_train_val.shape}\")\n",
    "    print(f\"  X_test: {X_test.shape}\")\n",
    "    \n",
    "    # 10. 클래스 분포 확인 (암호화폐 라벨)\n",
    "    print(f\"클래스 분포:\")\n",
    "    label_names = {0: 'Strong_Sell', 1: 'Hold', 2: 'Strong_Buy'}\n",
    "    \n",
    "    for name, y in [(\"훈련+검증\", y_train_val), (\"테스트\", y_test)]:\n",
    "        counts = y.value_counts().sort_index()\n",
    "        pcts = (counts / len(y) * 100).round(1)\n",
    "        \n",
    "        print(f\"  {name}:\")\n",
    "        for label, count in counts.items():\n",
    "            pct = pcts[label]\n",
    "            label_name = label_names.get(int(label), f'Label_{int(label)}')\n",
    "            print(f\"    {int(label)} ({label_name}): {count:,}개 ({pct}%)\")\n",
    "    \n",
    "    # 11. 클래스 균형도\n",
    "    class_ratio = y_train_val.value_counts().min() / y_train_val.value_counts().max()\n",
    "    print(f\"클래스 균형도: {class_ratio:.3f} (1.0에 가까울수록 균형)\")\n",
    "    \n",
    "    # 12. 데이터 검증\n",
    "    print(f\"데이터 검증:\")\n",
    "    print(f\"  결측치 - X_train_val: {X_train_val.isnull().sum().sum()}\")\n",
    "    print(f\"  결측치 - X_test: {X_test.isnull().sum().sum()}\")\n",
    "    print(f\"  무한값 - X_train_val: {np.isinf(X_train_val.values).sum()}\")\n",
    "    print(f\"  무한값 - X_test: {np.isinf(X_test.values).sum()}\")\n",
    "    \n",
    "    return X_train_val, X_test, y_train_val, y_test, feature_columns\n",
    "\n",
    "# 데이터 로드 실행\n",
    "X_train_val, X_test, y_train_val, y_test, feature_columns = load_and_prepare_crypto_data(data_dir)\n",
    "\n",
    "print(f\"데이터 준비 완료!\")\n",
    "print(f\"사용할 피쳐 수: {len(feature_columns)}\")\n",
    "print(f\"주요 피쳐들:\")\n",
    "for i, feat in enumerate(feature_columns[:15]):\n",
    "    print(f\"  {i+1:2d}. {feat}\")\n",
    "if len(feature_columns) > 15:\n",
    "    print(f\"  ... 외 {len(feature_columns)-15}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "256ddc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 가중치: {0.0: 1.6082449227038496, 0.8780000000000001: 5305.6, 1.0: 0.26632309880364763, 1.455000000000382: 5305.6, 2.0: 1.6051633723275514}\n",
      "CuPy 없음 - XGBoost 내장 GPU 메모리 관리 사용\n",
      "K-Fold 교차검증 설정 완료 (5폴드)\n",
      "모니터링 함수 설정 완료\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 셀 4: K-Fold 교차검증 설정 및 모니터링 함수\n",
    "# =============================================================================\n",
    "\n",
    "# K-Fold 설정\n",
    "kfold = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# 클래스 가중치 계산 함수\n",
    "def calculate_class_weights(y):\n",
    "    \"\"\"클래스 가중치 계산 (암호화폐 불균형 해결)\"\"\"\n",
    "    class_counts = y.value_counts().sort_index()\n",
    "    total_samples = len(y)\n",
    "    class_weights = {i: total_samples / (len(class_counts) * count) \n",
    "                    for i, count in class_counts.items()}\n",
    "    return class_weights\n",
    "\n",
    "# 클래스 가중치 확인\n",
    "class_weights = calculate_class_weights(y_train_val)\n",
    "print(f\"클래스 가중치: {class_weights}\")\n",
    "\n",
    "# 모니터링 함수들\n",
    "def check_gpu_memory():\n",
    "    \"\"\"GPU 메모리 사용률 체크\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total', \n",
    "                               '--format=csv,noheader,nounits'], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            gpu_util, mem_used, mem_total = result.stdout.strip().split(', ')\n",
    "            mem_percent = int(mem_used) / int(mem_total) * 100\n",
    "            return f\"GPU: {gpu_util}% | VRAM: {mem_percent:.1f}%\"\n",
    "        else:\n",
    "            return \"GPU 정보 없음\"\n",
    "    except:\n",
    "        return \"nvidia-smi 없음\"\n",
    "\n",
    "def check_system_memory():\n",
    "    \"\"\"시스템 메모리 사용률 체크\"\"\"\n",
    "    mem = psutil.virtual_memory()\n",
    "    return f\"RAM: {mem.percent:.1f}%\"\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"메모리 정리\"\"\"\n",
    "    gc.collect()\n",
    "    if USE_GPU:\n",
    "        try:\n",
    "            import torch\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# GPU 메모리 최적화\n",
    "def optimize_gpu_memory():\n",
    "    \"\"\"GPU 메모리 사용량 최적화\"\"\"\n",
    "    if USE_GPU:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "        os.environ['XGB_CUDA_MEMORY_POOL'] = '8192'  # 8GB GPU 메모리 풀\n",
    "        try:\n",
    "            import cupy\n",
    "            mempool = cupy.get_default_memory_pool()\n",
    "            mempool.set_limit(size=8 * 1024**3)  # 8GB 제한\n",
    "            print(\"GPU 메모리 풀 설정: 8GB\")\n",
    "        except:\n",
    "            print(\"CuPy 없음 - XGBoost 내장 GPU 메모리 관리 사용\")\n",
    "\n",
    "optimize_gpu_memory()\n",
    "print(f\"K-Fold 교차검증 설정 완료 ({N_FOLDS}폴드)\")\n",
    "print(\"모니터링 함수 설정 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5b7528ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 라벨 데이터 검증 및 전처리...\n",
      "y_train_val 원본 정보:\n",
      "  데이터 타입: float64\n",
      "  결측치 수: 0\n",
      "  고유값: [0.0, 0.8780000000000001, 1.0, 1.455000000000382, 2.0]\n",
      "  값 분포:\n",
      "Future_Label\n",
      "0.000     9897\n",
      "0.878        3\n",
      "1.000    59765\n",
      "1.455        3\n",
      "2.000     9916\n",
      "Name: count, dtype: int64\n",
      "\n",
      "정리 후 데이터:\n",
      "  X_train_val: (79584, 28)\n",
      "  y_train_val: (79584,)\n",
      "  데이터 타입: int64\n",
      "  라벨 분포:\n",
      "Future_Label\n",
      "0     9900\n",
      "1    59768\n",
      "2     9916\n",
      "Name: count, dtype: int64\n",
      "  최소 클래스 크기: 9900\n",
      "  최적 K-Fold 수: 5\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 데이터 전처리 및 검증 (Optuna 실행 전에 먼저 실행)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"📊 라벨 데이터 검증 및 전처리...\")\n",
    "\n",
    "# 1. y_train_val 데이터 타입 및 분포 확인\n",
    "print(f\"y_train_val 원본 정보:\")\n",
    "print(f\"  데이터 타입: {y_train_val.dtype}\")\n",
    "print(f\"  결측치 수: {y_train_val.isnull().sum()}\")\n",
    "print(f\"  고유값: {sorted(y_train_val.unique())}\")\n",
    "print(f\"  값 분포:\")\n",
    "print(y_train_val.value_counts().sort_index())\n",
    "\n",
    "# 2. 라벨 데이터 정리\n",
    "# NaN 제거 및 정수형 변환\n",
    "y_train_val_clean = y_train_val.dropna()\n",
    "X_train_val_clean = X_train_val.loc[y_train_val_clean.index]\n",
    "\n",
    "# 정수형으로 변환\n",
    "y_train_val_clean = y_train_val_clean.astype(int)\n",
    "\n",
    "# 유효한 라벨만 유지 (0, 1, 2)\n",
    "valid_mask = y_train_val_clean.isin([0, 1, 2])\n",
    "y_train_val_final = y_train_val_clean[valid_mask]\n",
    "X_train_val_final = X_train_val_clean.loc[y_train_val_final.index]\n",
    "\n",
    "print(f\"\\n정리 후 데이터:\")\n",
    "print(f\"  X_train_val: {X_train_val_final.shape}\")\n",
    "print(f\"  y_train_val: {y_train_val_final.shape}\")\n",
    "print(f\"  데이터 타입: {y_train_val_final.dtype}\")\n",
    "print(f\"  라벨 분포:\")\n",
    "print(y_train_val_final.value_counts().sort_index())\n",
    "\n",
    "# 클래스별 최소 샘플 수 확인\n",
    "min_class_size = y_train_val_final.value_counts().min()\n",
    "print(f\"  최소 클래스 크기: {min_class_size}\")\n",
    "\n",
    "# K-Fold 개수 조정 (최소 클래스 크기에 맞춰)\n",
    "optimal_k_folds = min(5, min_class_size // 2)  # 각 클래스가 최소 2개씩은 있도록\n",
    "print(f\"  최적 K-Fold 수: {optimal_k_folds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "80f2b389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 수정된 Optuna 목적 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 셀 5: 수정된 Optuna 목적 함수 정의\n",
    "# =============================================================================\n",
    "\n",
    "def objective_function(trial):\n",
    "    \"\"\"수정된 암호화폐용 Optuna 목적 함수\"\"\"\n",
    "    trial_num = trial.number + 1\n",
    "    \n",
    "    # 암호화폐에 특화된 파라미터 범위\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 3,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.25),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 800),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0),\n",
    "        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 2),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.1, 3),\n",
    "        'max_leaves': trial.suggest_int('max_leaves', 50, 300),\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'early_stopping_rounds': 50,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'n_jobs': PARALLEL_JOBS,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    # GPU 최적화 설정\n",
    "    if USE_GPU:\n",
    "        params['tree_method'] = 'gpu_hist'\n",
    "        params['gpu_id'] = 0\n",
    "        params['predictor'] = 'gpu_predictor'\n",
    "        params['max_bin'] = trial.suggest_int('max_bin', 256, 1024)\n",
    "        params['single_precision_histogram'] = True\n",
    "    \n",
    "    # 수정된 K-Fold 교차검증 (정리된 데이터 사용)\n",
    "    kfold_dynamic = StratifiedKFold(\n",
    "        n_splits=optimal_k_folds, \n",
    "        shuffle=True, \n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    cv_scores = []\n",
    "    \n",
    "    try:\n",
    "        for fold_num, (train_idx, val_idx) in enumerate(kfold_dynamic.split(X_train_val_final, y_train_val_final), 1):\n",
    "            X_train_fold = X_train_val_final.iloc[train_idx]\n",
    "            X_val_fold = X_train_val_final.iloc[val_idx]\n",
    "            y_train_fold = y_train_val_final.iloc[train_idx]\n",
    "            y_val_fold = y_train_val_final.iloc[val_idx]\n",
    "            \n",
    "            # 클래스 가중치 계산 (정수형 라벨 사용)\n",
    "            fold_class_weights = calculate_class_weights(y_train_fold)\n",
    "            sample_weights = np.array([fold_class_weights[label] for label in y_train_fold])\n",
    "            \n",
    "            # 모델 학습\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            model.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                sample_weight=sample_weights,\n",
    "                eval_set=[(X_val_fold, y_val_fold)],\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # 예측 및 평가\n",
    "            val_pred = model.predict(X_val_fold)\n",
    "            f1 = f1_score(y_val_fold, val_pred, average='macro')\n",
    "            cv_scores.append(f1)\n",
    "            \n",
    "            # 폴드 완료 후 정리\n",
    "            del model, val_pred\n",
    "            clear_memory()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial_num} 오류: {e}\")\n",
    "        return 0.0  # 실패한 경우 낮은 점수 반환\n",
    "    \n",
    "    if not cv_scores:  # 빈 리스트인 경우\n",
    "        return 0.0\n",
    "    \n",
    "    mean_cv_score = np.mean(cv_scores)\n",
    "    std_cv_score = np.std(cv_scores)\n",
    "    \n",
    "    print(f\"Trial {trial_num} 결과:\")\n",
    "    print(f\"  평균 CV F1-Score: {mean_cv_score:.4f} ± {std_cv_score:.4f}\")\n",
    "    print(f\"  개별 폴드 점수: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "    \n",
    "    # Trial 완료 후 메모리 정리\n",
    "    clear_memory()\n",
    "    \n",
    "    return mean_cv_score\n",
    "\n",
    "print(\"✅ 수정된 Optuna 목적 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf1fa0",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "78fba964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 03:21:48,462] A new study created in memory with name: no-name-4a3c7eb9-085a-40d1-9c4f-b7f11c3afae1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 하이퍼파라미터 최적화 시작...\n",
      "최적화 시도 횟수: 20회\n",
      "K-Fold 수: 5\n",
      "사용 데이터: (79584, 28)\n",
      "GPU 사용: True\n",
      "\n",
      "최종 라벨 분포:\n",
      "  0 (Sell): 9,900개 (12.4%)\n",
      "  1 (Hold): 59,768개 (75.1%)\n",
      "  2 (Buy): 9,916개 (12.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 03:22:27,197] Trial 0 finished with value: 0.4317890839149661 and parameters: {'max_depth': 7, 'learning_rate': 0.23817143353837988, 'n_estimators': 639, 'subsample': 0.8394633936788146, 'colsample_bytree': 0.6624074561769746, 'colsample_bylevel': 0.662397808134481, 'colsample_bynode': 0.6232334448672797, 'min_child_weight': 9, 'gamma': 3.005575058716044, 'reg_alpha': 1.416145155592091, 'reg_lambda': 0.1596950334578271, 'max_leaves': 293, 'grow_policy': 'depthwise', 'max_bin': 395}. Best is trial 0 with value: 0.4317890839149661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 결과:\n",
      "  평균 CV F1-Score: 0.4318 ± 0.0018\n",
      "  개별 폴드 점수: ['0.4324', '0.4313', '0.4286', '0.4329', '0.4337']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 03:24:25,287] Trial 1 finished with value: 0.43864761528016183 and parameters: {'max_depth': 5, 'learning_rate': 0.08301813831028905, 'n_estimators': 515, 'subsample': 0.7727780074568463, 'colsample_bytree': 0.7164916560792167, 'colsample_bylevel': 0.8447411578889518, 'colsample_bynode': 0.6557975442608167, 'min_child_weight': 3, 'gamma': 1.8318092164684585, 'reg_alpha': 0.9121399684340719, 'reg_lambda': 2.3770102880397395, 'max_leaves': 100, 'grow_policy': 'lossguide', 'max_bin': 291}. Best is trial 1 with value: 0.43864761528016183.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 결과:\n",
      "  평균 CV F1-Score: 0.4386 ± 0.0021\n",
      "  개별 폴드 점수: ['0.4366', '0.4414', '0.4363', '0.4381', '0.4408']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.4386\n",
      "  Best Trial: 2\n",
      "  남은 시도: 18회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 03:28:04,320] Trial 2 finished with value: 0.4420408185621484 and parameters: {'max_depth': 9, 'learning_rate': 0.05092578968494997, 'n_estimators': 239, 'subsample': 0.9795542149013333, 'colsample_bytree': 0.9862528132298237, 'colsample_bylevel': 0.9233589392465844, 'colsample_bynode': 0.7218455076693483, 'min_child_weight': 1, 'gamma': 3.4211651325607844, 'reg_alpha': 0.8803049874792026, 'reg_lambda': 0.45391088104985855, 'max_leaves': 174, 'grow_policy': 'lossguide', 'max_bin': 455}. Best is trial 2 with value: 0.4420408185621484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 결과:\n",
      "  평균 CV F1-Score: 0.4420 ± 0.0018\n",
      "  개별 폴드 점수: ['0.4402', '0.4418', '0.4439', '0.4400', '0.4444']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.4420\n",
      "  Best Trial: 3\n",
      "  남은 시도: 17회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 03:29:21,678] Trial 3 finished with value: 0.43089233601677374 and parameters: {'max_depth': 9, 'learning_rate': 0.08481065826145862, 'n_estimators': 512, 'subsample': 0.8186841117373118, 'colsample_bytree': 0.6739417822102108, 'colsample_bylevel': 0.9878338511058234, 'colsample_bynode': 0.9100531293444458, 'min_child_weight': 10, 'gamma': 4.474136752138244, 'reg_alpha': 1.1957999576221703, 'reg_lambda': 2.7734352815670387, 'max_leaves': 72, 'grow_policy': 'depthwise', 'max_bin': 506}. Best is trial 2 with value: 0.4420408185621484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 결과:\n",
      "  평균 CV F1-Score: 0.4309 ± 0.0016\n",
      "  개별 폴드 점수: ['0.4312', '0.4333', '0.4297', '0.4315', '0.4287']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.4420\n",
      "  Best Trial: 3\n",
      "  남은 시도: 16회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 03:40:33,089] Trial 4 finished with value: 0.49294789422619656 and parameters: {'max_depth': 7, 'learning_rate': 0.07512376762573501, 'n_estimators': 698, 'subsample': 0.7427013306774357, 'colsample_bytree': 0.7123738038749523, 'colsample_bylevel': 0.8170784332632994, 'colsample_bynode': 0.6563696899899051, 'min_child_weight': 9, 'gamma': 0.3727532183988541, 'reg_alpha': 1.9737738732010346, 'reg_lambda': 2.3395098309603064, 'max_leaves': 99, 'grow_policy': 'lossguide', 'max_bin': 799}. Best is trial 4 with value: 0.49294789422619656.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 결과:\n",
      "  평균 CV F1-Score: 0.4929 ± 0.0026\n",
      "  개별 폴드 점수: ['0.4891', '0.4969', '0.4923', '0.4924', '0.4940']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.4929\n",
      "  Best Trial: 5\n",
      "  남은 시도: 15회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 03:53:33,881] Trial 5 finished with value: 0.5371745414960061 and parameters: {'max_depth': 10, 'learning_rate': 0.195104883204627, 'n_estimators': 244, 'subsample': 0.7433862914177091, 'colsample_bytree': 0.6463476238100518, 'colsample_bylevel': 0.9452413703502374, 'colsample_bynode': 0.8493192507310232, 'min_child_weight': 4, 'gamma': 0.3177917514301182, 'reg_alpha': 0.6219646434313244, 'reg_lambda': 1.0430316338775665, 'max_leaves': 233, 'grow_policy': 'lossguide', 'max_bin': 619}. Best is trial 5 with value: 0.5371745414960061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 결과:\n",
      "  평균 CV F1-Score: 0.5372 ± 0.0030\n",
      "  개별 폴드 점수: ['0.5324', '0.5406', '0.5364', '0.5402', '0.5362']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5372\n",
      "  Best Trial: 6\n",
      "  남은 시도: 14회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 03:59:07,035] Trial 6 finished with value: 0.4935956000217547 and parameters: {'max_depth': 5, 'learning_rate': 0.1811787489335188, 'n_estimators': 657, 'subsample': 0.8245108790277985, 'colsample_bytree': 0.9083868719818244, 'colsample_bylevel': 0.7975182385457563, 'colsample_bynode': 0.8090931317527976, 'min_child_weight': 5, 'gamma': 0.12709563372047594, 'reg_alpha': 0.2157828539866089, 'reg_lambda': 0.19114463849152935, 'max_leaves': 209, 'grow_policy': 'lossguide', 'max_bin': 953}. Best is trial 5 with value: 0.5371745414960061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 결과:\n",
      "  평균 CV F1-Score: 0.4936 ± 0.0023\n",
      "  개별 폴드 점수: ['0.4916', '0.4960', '0.4901', '0.4948', '0.4955']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5372\n",
      "  Best Trial: 6\n",
      "  남은 시도: 13회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 04:00:10,657] Trial 7 finished with value: 0.4257594786076315 and parameters: {'max_depth': 6, 'learning_rate': 0.10849190152855112, 'n_estimators': 654, 'subsample': 0.6915192661966489, 'colsample_bytree': 0.6307919639315172, 'colsample_bylevel': 0.7159005811655073, 'colsample_bynode': 0.6644885149016018, 'min_child_weight': 10, 'gamma': 4.040601897822085, 'reg_alpha': 1.266807513020847, 'reg_lambda': 2.6272357115443814, 'max_leaves': 251, 'grow_policy': 'lossguide', 'max_bin': 670}. Best is trial 5 with value: 0.5371745414960061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 결과:\n",
      "  평균 CV F1-Score: 0.4258 ± 0.0020\n",
      "  개별 폴드 점수: ['0.4285', '0.4275', '0.4244', '0.4231', '0.4253']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5372\n",
      "  Best Trial: 6\n",
      "  남은 시도: 12회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 04:16:30,896] Trial 8 finished with value: 0.5391506283854346 and parameters: {'max_depth': 11, 'learning_rate': 0.22506191198163839, 'n_estimators': 391, 'subsample': 0.6440207698110707, 'colsample_bytree': 0.6911740650167767, 'colsample_bylevel': 0.7708431154505025, 'colsample_bynode': 0.9272059063689972, 'min_child_weight': 9, 'gamma': 0.03476065265595352, 'reg_alpha': 1.0214946051551315, 'reg_lambda': 1.310491909131459, 'max_leaves': 105, 'grow_policy': 'lossguide', 'max_bin': 981}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 결과:\n",
      "  평균 CV F1-Score: 0.5392 ± 0.0043\n",
      "  개별 폴드 점수: ['0.5332', '0.5448', '0.5356', '0.5429', '0.5392']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 11회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 04:19:05,487] Trial 9 finished with value: 0.46774043529935005 and parameters: {'max_depth': 6, 'learning_rate': 0.13450974921840786, 'n_estimators': 622, 'subsample': 0.7454518409517176, 'colsample_bytree': 0.9887128330883843, 'colsample_bylevel': 0.9849789179768444, 'colsample_bynode': 0.7007129183301457, 'min_child_weight': 5, 'gamma': 1.5043915490838482, 'reg_alpha': 0.5696809887549352, 'reg_lambda': 0.20697214732814512, 'max_leaves': 203, 'grow_policy': 'depthwise', 'max_bin': 470}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 결과:\n",
      "  평균 CV F1-Score: 0.4677 ± 0.0037\n",
      "  개별 폴드 점수: ['0.4615', '0.4720', '0.4658', '0.4697', '0.4697']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 10회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 04:31:07,001] Trial 10 finished with value: 0.44828854073464 and parameters: {'max_depth': 12, 'learning_rate': 0.011439323909396115, 'n_estimators': 362, 'subsample': 0.6071847502459279, 'colsample_bytree': 0.8010124870699186, 'colsample_bylevel': 0.6154900799844731, 'colsample_bynode': 0.9880188644633204, 'min_child_weight': 7, 'gamma': 1.4080316779931286, 'reg_alpha': 1.6698974038108552, 'reg_lambda': 1.6297708597516292, 'max_leaves': 150, 'grow_policy': 'depthwise', 'max_bin': 1018}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 결과:\n",
      "  평균 CV F1-Score: 0.4483 ± 0.0019\n",
      "  개별 폴드 점수: ['0.4457', '0.4505', '0.4466', '0.4485', '0.4501']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 9회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 04:38:13,949] Trial 11 finished with value: 0.518591452703233 and parameters: {'max_depth': 12, 'learning_rate': 0.24016028314003307, 'n_estimators': 204, 'subsample': 0.62041203080207, 'colsample_bytree': 0.6024475611716448, 'colsample_bylevel': 0.7550376816255844, 'colsample_bynode': 0.8612012640576854, 'min_child_weight': 7, 'gamma': 0.6985986279773649, 'reg_alpha': 0.5489699465649617, 'reg_lambda': 1.1081369484400898, 'max_leaves': 147, 'grow_policy': 'lossguide', 'max_bin': 681}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 결과:\n",
      "  평균 CV F1-Score: 0.5186 ± 0.0031\n",
      "  개별 폴드 점수: ['0.5126', '0.5201', '0.5196', '0.5212', '0.5195']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 8회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 04:44:08,062] Trial 12 finished with value: 0.5041537132254634 and parameters: {'max_depth': 10, 'learning_rate': 0.1934371228522767, 'n_estimators': 350, 'subsample': 0.6777315298393309, 'colsample_bytree': 0.7987586652315627, 'colsample_bylevel': 0.8905916035440609, 'colsample_bynode': 0.937592040684478, 'min_child_weight': 3, 'gamma': 0.9446300501258088, 'reg_alpha': 0.5763947263712728, 'reg_lambda': 1.2026306881744562, 'max_leaves': 50, 'grow_policy': 'lossguide', 'max_bin': 833}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 결과:\n",
      "  평균 CV F1-Score: 0.5042 ± 0.0028\n",
      "  개별 폴드 점수: ['0.5003', '0.5091', '0.5043', '0.5036', '0.5035']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 7회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 04:46:24,688] Trial 13 finished with value: 0.46281815064991944 and parameters: {'max_depth': 11, 'learning_rate': 0.189102266933963, 'n_estimators': 353, 'subsample': 0.9032894468052295, 'colsample_bytree': 0.766600347730197, 'colsample_bylevel': 0.734190463327493, 'colsample_bynode': 0.8086447544742145, 'min_child_weight': 7, 'gamma': 2.009605065619801, 'reg_alpha': 0.3418987711434412, 'reg_lambda': 1.691274361509663, 'max_leaves': 247, 'grow_policy': 'lossguide', 'max_bin': 586}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 결과:\n",
      "  평균 CV F1-Score: 0.4628 ± 0.0023\n",
      "  개별 폴드 점수: ['0.4603', '0.4642', '0.4603', '0.4629', '0.4664']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 6회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 04:58:55,432] Trial 14 finished with value: 0.53003351915201 and parameters: {'max_depth': 10, 'learning_rate': 0.15138345078902593, 'n_estimators': 302, 'subsample': 0.6751972582409602, 'colsample_bytree': 0.7322630983647145, 'colsample_bylevel': 0.8907859007152179, 'colsample_bynode': 0.8777509257385601, 'min_child_weight': 3, 'gamma': 0.013326046860945046, 'reg_alpha': 0.04739082301166442, 'reg_lambda': 0.9520624014944143, 'max_leaves': 112, 'grow_policy': 'lossguide', 'max_bin': 772}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 결과:\n",
      "  평균 CV F1-Score: 0.5300 ± 0.0043\n",
      "  개별 폴드 점수: ['0.5249', '0.5358', '0.5255', '0.5333', '0.5307']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 5회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 05:05:58,092] Trial 15 finished with value: 0.5222098871338424 and parameters: {'max_depth': 11, 'learning_rate': 0.21440146085950093, 'n_estimators': 456, 'subsample': 0.7058633882518718, 'colsample_bytree': 0.8805019670280213, 'colsample_bylevel': 0.7839944835498075, 'colsample_bynode': 0.9611746250608352, 'min_child_weight': 1, 'gamma': 0.9513356534099786, 'reg_alpha': 0.8066467220256239, 'reg_lambda': 0.7478114830032362, 'max_leaves': 244, 'grow_policy': 'lossguide', 'max_bin': 885}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 결과:\n",
      "  평균 CV F1-Score: 0.5222 ± 0.0047\n",
      "  개별 폴드 점수: ['0.5160', '0.5285', '0.5179', '0.5227', '0.5259']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 4회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 05:07:42,661] Trial 16 finished with value: 0.44463627389890314 and parameters: {'max_depth': 9, 'learning_rate': 0.15328297328795543, 'n_estimators': 426, 'subsample': 0.6418110931963766, 'colsample_bytree': 0.6619819703672106, 'colsample_bylevel': 0.6819176271579093, 'colsample_bynode': 0.7589042806088715, 'min_child_weight': 6, 'gamma': 2.5941269374331046, 'reg_alpha': 1.0952680963618822, 'reg_lambda': 1.9482756122127856, 'max_leaves': 293, 'grow_policy': 'lossguide', 'max_bin': 625}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17 결과:\n",
      "  평균 CV F1-Score: 0.4446 ± 0.0013\n",
      "  개별 폴드 점수: ['0.4438', '0.4464', '0.4426', '0.4456', '0.4448']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 3회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 05:14:01,424] Trial 17 finished with value: 0.5128185053744402 and parameters: {'max_depth': 11, 'learning_rate': 0.21856465380731244, 'n_estimators': 279, 'subsample': 0.7268374282556763, 'colsample_bytree': 0.6092045864341958, 'colsample_bylevel': 0.9355520901109741, 'colsample_bynode': 0.8557475403288582, 'min_child_weight': 4, 'gamma': 0.7441614302847561, 'reg_alpha': 1.5223966419719628, 'reg_lambda': 1.3956438153077009, 'max_leaves': 131, 'grow_policy': 'lossguide', 'max_bin': 715}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18 결과:\n",
      "  평균 CV F1-Score: 0.5128 ± 0.0035\n",
      "  개별 폴드 점수: ['0.5077', '0.5150', '0.5104', '0.5132', '0.5178']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 2회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 05:14:41,596] Trial 18 finished with value: 0.42962144432575167 and parameters: {'max_depth': 8, 'learning_rate': 0.16933894770312002, 'n_estimators': 411, 'subsample': 0.8759710886560624, 'colsample_bytree': 0.7596641733462661, 'colsample_bylevel': 0.8396815651256182, 'colsample_bynode': 0.8988350397643667, 'min_child_weight': 8, 'gamma': 4.996467385418862, 'reg_alpha': 0.6782380447304142, 'reg_lambda': 0.6996355916121462, 'max_leaves': 200, 'grow_policy': 'depthwise', 'max_bin': 555}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19 결과:\n",
      "  평균 CV F1-Score: 0.4296 ± 0.0016\n",
      "  개별 폴드 점수: ['0.4313', '0.4311', '0.4295', '0.4269', '0.4293']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 1회\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-28 05:16:58,468] Trial 19 finished with value: 0.4664367544268188 and parameters: {'max_depth': 10, 'learning_rate': 0.24985923858104447, 'n_estimators': 781, 'subsample': 0.6512724702232536, 'colsample_bytree': 0.6879350499169388, 'colsample_bylevel': 0.8658452477859441, 'colsample_bynode': 0.8338171176295528, 'min_child_weight': 4, 'gamma': 2.2653392633121174, 'reg_alpha': 0.35302365926526263, 'reg_lambda': 1.833883131947237, 'max_leaves': 175, 'grow_policy': 'lossguide', 'max_bin': 909}. Best is trial 8 with value: 0.5391506283854346.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 결과:\n",
      "  평균 CV F1-Score: 0.4664 ± 0.0021\n",
      "  개별 폴드 점수: ['0.4648', '0.4637', '0.4661', '0.4682', '0.4693']\n",
      "\n",
      "현재까지 최고 성능:\n",
      "  Best F1-Score: 0.5392\n",
      "  Best Trial: 9\n",
      "  남은 시도: 0회\n",
      "--------------------------------------------------\n",
      "============================================================\n",
      "🎉 하이퍼파라미터 최적화 완료!\n",
      "============================================================\n",
      "최고 CV F1-Score: 0.5392\n",
      "최고 성능을 낸 Trial: 9\n",
      "사용된 K-Fold 수: 5\n",
      "\n",
      "최적 파라미터:\n",
      "  max_depth: 11\n",
      "  learning_rate: 0.22506191198163839\n",
      "  n_estimators: 391\n",
      "  subsample: 0.6440207698110707\n",
      "  colsample_bytree: 0.6911740650167767\n",
      "  colsample_bylevel: 0.7708431154505025\n",
      "  colsample_bynode: 0.9272059063689972\n",
      "  min_child_weight: 9\n",
      "  gamma: 0.03476065265595352\n",
      "  reg_alpha: 1.0214946051551315\n",
      "  reg_lambda: 1.310491909131459\n",
      "  max_leaves: 105\n",
      "  grow_policy: lossguide\n",
      "  max_bin: 981\n",
      "\n",
      "Top 5 시도 결과:\n",
      "  1. Trial 9: F1-Score 0.5392\n",
      "  2. Trial 6: F1-Score 0.5372\n",
      "  3. Trial 15: F1-Score 0.5300\n",
      "  4. Trial 16: F1-Score 0.5222\n",
      "  5. Trial 12: F1-Score 0.5186\n",
      "\n",
      "✅ 최적화 프로세스 완료\n",
      "\n",
      "📊 전역 변수 업데이트 완료:\n",
      "  X_train_val: (79584, 28)\n",
      "  y_train_val: (79584,)\n",
      "  라벨 타입: int64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 셀 6: 하이퍼파라미터 최적화 실행\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🚀 하이퍼파라미터 최적화 시작...\")\n",
    "print(f\"최적화 시도 횟수: {N_TRIALS}회\")\n",
    "print(f\"K-Fold 수: {optimal_k_folds}\")\n",
    "print(f\"사용 데이터: {X_train_val_final.shape}\")\n",
    "print(f\"GPU 사용: {USE_GPU}\")\n",
    "\n",
    "# 최종 데이터 검증\n",
    "print(f\"\\n최종 라벨 분포:\")\n",
    "for label, count in y_train_val_final.value_counts().sort_index().items():\n",
    "    label_name = {0: 'Sell', 1: 'Hold', 2: 'Buy'}[label]\n",
    "    pct = count / len(y_train_val_final) * 100\n",
    "    print(f\"  {label} ({label_name}): {count:,}개 ({pct:.1f}%)\")\n",
    "\n",
    "# Optuna Study 생성\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=TPESampler(seed=RANDOM_STATE)\n",
    ")\n",
    "\n",
    "# 최적화 실행\n",
    "def print_best_callback(study, trial):\n",
    "    \"\"\"각 trial 후 현재까지 최고 성능 출력\"\"\"\n",
    "    if trial.number > 0:\n",
    "        print(f\"\\n현재까지 최고 성능:\")\n",
    "        print(f\"  Best F1-Score: {study.best_value:.4f}\")\n",
    "        print(f\"  Best Trial: {study.best_trial.number + 1}\")\n",
    "        print(f\"  남은 시도: {N_TRIALS - trial.number - 1}회\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    study.optimize(objective_function, n_trials=N_TRIALS, callbacks=[print_best_callback])\n",
    "    \n",
    "    # 결과 저장\n",
    "    best_params = study.best_params\n",
    "    best_cv_score = study.best_value\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"🎉 하이퍼파라미터 최적화 완료!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"최고 CV F1-Score: {best_cv_score:.4f}\")\n",
    "    print(f\"최고 성능을 낸 Trial: {study.best_trial.number + 1}\")\n",
    "    print(f\"사용된 K-Fold 수: {optimal_k_folds}\")\n",
    "    print(f\"\\n최적 파라미터:\")\n",
    "    for key, value in best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Top 5 시도 결과 출력\n",
    "    print(f\"\\nTop 5 시도 결과:\")\n",
    "    sorted_trials = sorted(study.trials, key=lambda x: x.value if x.value else 0, reverse=True)[:5]\n",
    "    for i, trial in enumerate(sorted_trials, 1):\n",
    "        if trial.value:\n",
    "            print(f\"  {i}. Trial {trial.number + 1}: F1-Score {trial.value:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 최적화 중 오류 발생: {e}\")\n",
    "    print(\"데이터를 다시 확인해주세요.\")\n",
    "\n",
    "print(f\"\\n✅ 최적화 프로세스 완료\")\n",
    "\n",
    "# =============================================================================\n",
    "# 추가: 정리된 데이터를 전역 변수로 업데이트 (다음 셀에서 사용하기 위해)\n",
    "# =============================================================================\n",
    "\n",
    "# 다음 셀들에서 사용할 수 있도록 정리된 데이터로 업데이트\n",
    "X_train_val = X_train_val_final\n",
    "y_train_val = y_train_val_final\n",
    "\n",
    "print(f\"\\n📊 전역 변수 업데이트 완료:\")\n",
    "print(f\"  X_train_val: {X_train_val.shape}\")\n",
    "print(f\"  y_train_val: {y_train_val.shape}\")\n",
    "print(f\"  라벨 타입: {y_train_val.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e2f5077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 모델 학습 시작...\n",
      "학습 전 상태 | GPU: 30% | VRAM: 16.0% | RAM: 18.8%\n",
      "GPU 가속 사용\n",
      "최종 모델 파라미터:\n",
      "  max_depth: 11\n",
      "  learning_rate: 0.22506191198163839\n",
      "  n_estimators: 391\n",
      "  subsample: 0.6440207698110707\n",
      "  colsample_bytree: 0.6911740650167767\n",
      "  colsample_bylevel: 0.7708431154505025\n",
      "  colsample_bynode: 0.9272059063689972\n",
      "  min_child_weight: 9\n",
      "  gamma: 0.03476065265595352\n",
      "  reg_alpha: 1.0214946051551315\n",
      "  reg_lambda: 1.310491909131459\n",
      "  max_leaves: 105\n",
      "  grow_policy: lossguide\n",
      "  max_bin: 981\n",
      "  objective: multi:softprob\n",
      "  num_class: 3\n",
      "  eval_metric: mlogloss\n",
      "  random_state: 42\n",
      "  n_jobs: 1\n",
      "  verbosity: 1\n",
      "  tree_method: gpu_hist\n",
      "  gpu_id: 0\n",
      "  predictor: gpu_predictor\n",
      "  single_precision_histogram: True\n",
      "클래스 가중치 적용: {0.0: 1.6082449227038496, 0.8780000000000001: 5305.6, 1.0: 0.26632309880364763, 1.455000000000382: 5305.6, 2.0: 1.6051633723275514}\n",
      "학습 준비 완료 | GPU: 30% | VRAM: 16.2% | RAM: 18.8%\n",
      "최종 모델 학습 진행...\n",
      "[0]\tvalidation_0-mlogloss:1.06322\n",
      "[1]\tvalidation_0-mlogloss:1.04023\n",
      "[2]\tvalidation_0-mlogloss:1.01394\n",
      "[3]\tvalidation_0-mlogloss:0.99467\n",
      "[4]\tvalidation_0-mlogloss:0.98517\n",
      "[5]\tvalidation_0-mlogloss:0.97345\n",
      "[6]\tvalidation_0-mlogloss:0.96294\n",
      "[7]\tvalidation_0-mlogloss:0.95398\n",
      "[8]\tvalidation_0-mlogloss:0.94482\n",
      "[9]\tvalidation_0-mlogloss:0.93873\n",
      "[10]\tvalidation_0-mlogloss:0.93047\n",
      "[11]\tvalidation_0-mlogloss:0.92290\n",
      "[12]\tvalidation_0-mlogloss:0.91748\n",
      "[13]\tvalidation_0-mlogloss:0.91293\n",
      "[14]\tvalidation_0-mlogloss:0.90714\n",
      "[15]\tvalidation_0-mlogloss:0.90301\n",
      "[16]\tvalidation_0-mlogloss:0.90004\n",
      "[17]\tvalidation_0-mlogloss:0.89653\n",
      "[18]\tvalidation_0-mlogloss:0.89291\n",
      "[19]\tvalidation_0-mlogloss:0.88993\n",
      "[20]\tvalidation_0-mlogloss:0.88702\n",
      "[21]\tvalidation_0-mlogloss:0.88432\n",
      "[22]\tvalidation_0-mlogloss:0.88173\n",
      "[23]\tvalidation_0-mlogloss:0.87940\n",
      "[24]\tvalidation_0-mlogloss:0.87685\n",
      "[25]\tvalidation_0-mlogloss:0.87496\n",
      "[26]\tvalidation_0-mlogloss:0.87277\n",
      "[27]\tvalidation_0-mlogloss:0.87059\n",
      "[28]\tvalidation_0-mlogloss:0.86793\n",
      "[29]\tvalidation_0-mlogloss:0.86701\n",
      "[30]\tvalidation_0-mlogloss:0.86657\n",
      "[31]\tvalidation_0-mlogloss:0.86421\n",
      "[32]\tvalidation_0-mlogloss:0.86345\n",
      "[33]\tvalidation_0-mlogloss:0.86222\n",
      "[34]\tvalidation_0-mlogloss:0.86118\n",
      "[35]\tvalidation_0-mlogloss:0.86029\n",
      "[36]\tvalidation_0-mlogloss:0.85892\n",
      "[37]\tvalidation_0-mlogloss:0.85779\n",
      "[38]\tvalidation_0-mlogloss:0.85719\n",
      "[39]\tvalidation_0-mlogloss:0.85674\n",
      "[40]\tvalidation_0-mlogloss:0.85598\n",
      "[41]\tvalidation_0-mlogloss:0.85523\n",
      "[42]\tvalidation_0-mlogloss:0.85396\n",
      "[43]\tvalidation_0-mlogloss:0.85357\n",
      "[44]\tvalidation_0-mlogloss:0.85348\n",
      "[45]\tvalidation_0-mlogloss:0.85148\n",
      "[46]\tvalidation_0-mlogloss:0.85003\n",
      "[47]\tvalidation_0-mlogloss:0.84867\n",
      "[48]\tvalidation_0-mlogloss:0.84862\n",
      "[49]\tvalidation_0-mlogloss:0.84777\n",
      "[50]\tvalidation_0-mlogloss:0.84596\n",
      "[51]\tvalidation_0-mlogloss:0.84502\n",
      "[52]\tvalidation_0-mlogloss:0.84328\n",
      "[53]\tvalidation_0-mlogloss:0.84212\n",
      "[54]\tvalidation_0-mlogloss:0.84164\n",
      "[55]\tvalidation_0-mlogloss:0.84012\n",
      "[56]\tvalidation_0-mlogloss:0.83914\n",
      "[57]\tvalidation_0-mlogloss:0.83948\n",
      "[58]\tvalidation_0-mlogloss:0.83865\n",
      "[59]\tvalidation_0-mlogloss:0.83781\n",
      "[60]\tvalidation_0-mlogloss:0.83691\n",
      "[61]\tvalidation_0-mlogloss:0.83650\n",
      "[62]\tvalidation_0-mlogloss:0.83537\n",
      "[63]\tvalidation_0-mlogloss:0.83512\n",
      "[64]\tvalidation_0-mlogloss:0.83470\n",
      "[65]\tvalidation_0-mlogloss:0.83439\n",
      "[66]\tvalidation_0-mlogloss:0.83401\n",
      "[67]\tvalidation_0-mlogloss:0.83343\n",
      "[68]\tvalidation_0-mlogloss:0.83214\n",
      "[69]\tvalidation_0-mlogloss:0.83144\n",
      "[70]\tvalidation_0-mlogloss:0.83091\n",
      "[71]\tvalidation_0-mlogloss:0.83089\n",
      "[72]\tvalidation_0-mlogloss:0.82995\n",
      "[73]\tvalidation_0-mlogloss:0.82919\n",
      "[74]\tvalidation_0-mlogloss:0.82786\n",
      "[75]\tvalidation_0-mlogloss:0.82719\n",
      "[76]\tvalidation_0-mlogloss:0.82651\n",
      "[77]\tvalidation_0-mlogloss:0.82566\n",
      "[78]\tvalidation_0-mlogloss:0.82583\n",
      "[79]\tvalidation_0-mlogloss:0.82552\n",
      "[80]\tvalidation_0-mlogloss:0.82425\n",
      "[81]\tvalidation_0-mlogloss:0.82327\n",
      "[82]\tvalidation_0-mlogloss:0.82267\n",
      "[83]\tvalidation_0-mlogloss:0.82208\n",
      "[84]\tvalidation_0-mlogloss:0.82176\n",
      "[85]\tvalidation_0-mlogloss:0.82154\n",
      "[86]\tvalidation_0-mlogloss:0.82133\n",
      "[87]\tvalidation_0-mlogloss:0.82033\n",
      "[88]\tvalidation_0-mlogloss:0.81967\n",
      "[89]\tvalidation_0-mlogloss:0.81855\n",
      "[90]\tvalidation_0-mlogloss:0.81768\n",
      "[91]\tvalidation_0-mlogloss:0.81710\n",
      "[92]\tvalidation_0-mlogloss:0.81674\n",
      "[93]\tvalidation_0-mlogloss:0.81572\n",
      "[94]\tvalidation_0-mlogloss:0.81498\n",
      "[95]\tvalidation_0-mlogloss:0.81437\n",
      "[96]\tvalidation_0-mlogloss:0.81389\n",
      "[97]\tvalidation_0-mlogloss:0.81350\n",
      "[98]\tvalidation_0-mlogloss:0.81267\n",
      "[99]\tvalidation_0-mlogloss:0.81273\n",
      "[100]\tvalidation_0-mlogloss:0.81222\n",
      "[101]\tvalidation_0-mlogloss:0.81159\n",
      "[102]\tvalidation_0-mlogloss:0.81147\n",
      "[103]\tvalidation_0-mlogloss:0.80988\n",
      "[104]\tvalidation_0-mlogloss:0.80970\n",
      "[105]\tvalidation_0-mlogloss:0.80993\n",
      "[106]\tvalidation_0-mlogloss:0.80965\n",
      "[107]\tvalidation_0-mlogloss:0.80902\n",
      "[108]\tvalidation_0-mlogloss:0.80841\n",
      "[109]\tvalidation_0-mlogloss:0.80851\n",
      "[110]\tvalidation_0-mlogloss:0.80779\n",
      "[111]\tvalidation_0-mlogloss:0.80701\n",
      "[112]\tvalidation_0-mlogloss:0.80639\n",
      "[113]\tvalidation_0-mlogloss:0.80556\n",
      "[114]\tvalidation_0-mlogloss:0.80457\n",
      "[115]\tvalidation_0-mlogloss:0.80412\n",
      "[116]\tvalidation_0-mlogloss:0.80315\n",
      "[117]\tvalidation_0-mlogloss:0.80258\n",
      "[118]\tvalidation_0-mlogloss:0.80238\n",
      "[119]\tvalidation_0-mlogloss:0.80199\n",
      "[120]\tvalidation_0-mlogloss:0.80156\n",
      "[121]\tvalidation_0-mlogloss:0.80114\n",
      "[122]\tvalidation_0-mlogloss:0.80020\n",
      "[123]\tvalidation_0-mlogloss:0.79925\n",
      "[124]\tvalidation_0-mlogloss:0.79880\n",
      "[125]\tvalidation_0-mlogloss:0.79819\n",
      "[126]\tvalidation_0-mlogloss:0.79823\n",
      "[127]\tvalidation_0-mlogloss:0.79854\n",
      "[128]\tvalidation_0-mlogloss:0.79760\n",
      "[129]\tvalidation_0-mlogloss:0.79733\n",
      "[130]\tvalidation_0-mlogloss:0.79693\n",
      "[131]\tvalidation_0-mlogloss:0.79718\n",
      "[132]\tvalidation_0-mlogloss:0.79663\n",
      "[133]\tvalidation_0-mlogloss:0.79585\n",
      "[134]\tvalidation_0-mlogloss:0.79470\n",
      "[135]\tvalidation_0-mlogloss:0.79507\n",
      "[136]\tvalidation_0-mlogloss:0.79459\n",
      "[137]\tvalidation_0-mlogloss:0.79465\n",
      "[138]\tvalidation_0-mlogloss:0.79375\n",
      "[139]\tvalidation_0-mlogloss:0.79299\n",
      "[140]\tvalidation_0-mlogloss:0.79274\n",
      "[141]\tvalidation_0-mlogloss:0.79240\n",
      "[142]\tvalidation_0-mlogloss:0.79262\n",
      "[143]\tvalidation_0-mlogloss:0.79247\n",
      "[144]\tvalidation_0-mlogloss:0.79206\n",
      "[145]\tvalidation_0-mlogloss:0.79131\n",
      "[146]\tvalidation_0-mlogloss:0.79054\n",
      "[147]\tvalidation_0-mlogloss:0.79037\n",
      "[148]\tvalidation_0-mlogloss:0.78971\n",
      "[149]\tvalidation_0-mlogloss:0.78984\n",
      "[150]\tvalidation_0-mlogloss:0.78926\n",
      "[151]\tvalidation_0-mlogloss:0.78862\n",
      "[152]\tvalidation_0-mlogloss:0.78895\n",
      "[153]\tvalidation_0-mlogloss:0.78885\n",
      "[154]\tvalidation_0-mlogloss:0.78850\n",
      "[155]\tvalidation_0-mlogloss:0.78807\n",
      "[156]\tvalidation_0-mlogloss:0.78796\n",
      "[157]\tvalidation_0-mlogloss:0.78716\n",
      "[158]\tvalidation_0-mlogloss:0.78693\n",
      "[159]\tvalidation_0-mlogloss:0.78577\n",
      "[160]\tvalidation_0-mlogloss:0.78587\n",
      "[161]\tvalidation_0-mlogloss:0.78482\n",
      "[162]\tvalidation_0-mlogloss:0.78423\n",
      "[163]\tvalidation_0-mlogloss:0.78358\n",
      "[164]\tvalidation_0-mlogloss:0.78374\n",
      "[165]\tvalidation_0-mlogloss:0.78299\n",
      "[166]\tvalidation_0-mlogloss:0.78241\n",
      "[167]\tvalidation_0-mlogloss:0.78235\n",
      "[168]\tvalidation_0-mlogloss:0.78267\n",
      "[169]\tvalidation_0-mlogloss:0.78226\n",
      "[170]\tvalidation_0-mlogloss:0.78223\n",
      "[171]\tvalidation_0-mlogloss:0.78204\n",
      "[172]\tvalidation_0-mlogloss:0.78170\n",
      "[173]\tvalidation_0-mlogloss:0.78084\n",
      "[174]\tvalidation_0-mlogloss:0.77991\n",
      "[175]\tvalidation_0-mlogloss:0.77989\n",
      "[176]\tvalidation_0-mlogloss:0.77998\n",
      "[177]\tvalidation_0-mlogloss:0.78011\n",
      "[178]\tvalidation_0-mlogloss:0.77919\n",
      "[179]\tvalidation_0-mlogloss:0.77854\n",
      "[180]\tvalidation_0-mlogloss:0.77808\n",
      "[181]\tvalidation_0-mlogloss:0.77783\n",
      "[182]\tvalidation_0-mlogloss:0.77769\n",
      "[183]\tvalidation_0-mlogloss:0.77814\n",
      "[184]\tvalidation_0-mlogloss:0.77721\n",
      "[185]\tvalidation_0-mlogloss:0.77643\n",
      "[186]\tvalidation_0-mlogloss:0.77639\n",
      "[187]\tvalidation_0-mlogloss:0.77683\n",
      "[188]\tvalidation_0-mlogloss:0.77637\n",
      "[189]\tvalidation_0-mlogloss:0.77585\n",
      "[190]\tvalidation_0-mlogloss:0.77572\n",
      "[191]\tvalidation_0-mlogloss:0.77541\n",
      "[192]\tvalidation_0-mlogloss:0.77495\n",
      "[193]\tvalidation_0-mlogloss:0.77494\n",
      "[194]\tvalidation_0-mlogloss:0.77430\n",
      "[195]\tvalidation_0-mlogloss:0.77421\n",
      "[196]\tvalidation_0-mlogloss:0.77335\n",
      "[197]\tvalidation_0-mlogloss:0.77341\n",
      "[198]\tvalidation_0-mlogloss:0.77278\n",
      "[199]\tvalidation_0-mlogloss:0.77240\n",
      "[200]\tvalidation_0-mlogloss:0.77248\n",
      "[201]\tvalidation_0-mlogloss:0.77150\n",
      "[202]\tvalidation_0-mlogloss:0.77068\n",
      "[203]\tvalidation_0-mlogloss:0.77014\n",
      "[204]\tvalidation_0-mlogloss:0.76970\n",
      "[205]\tvalidation_0-mlogloss:0.76919\n",
      "[206]\tvalidation_0-mlogloss:0.76884\n",
      "[207]\tvalidation_0-mlogloss:0.76849\n",
      "[208]\tvalidation_0-mlogloss:0.76811\n",
      "[209]\tvalidation_0-mlogloss:0.76753\n",
      "[210]\tvalidation_0-mlogloss:0.76756\n",
      "[211]\tvalidation_0-mlogloss:0.76724\n",
      "[212]\tvalidation_0-mlogloss:0.76659\n",
      "[213]\tvalidation_0-mlogloss:0.76644\n",
      "[214]\tvalidation_0-mlogloss:0.76649\n",
      "[215]\tvalidation_0-mlogloss:0.76612\n",
      "[216]\tvalidation_0-mlogloss:0.76583\n",
      "[217]\tvalidation_0-mlogloss:0.76535\n",
      "[218]\tvalidation_0-mlogloss:0.76463\n",
      "[219]\tvalidation_0-mlogloss:0.76419\n",
      "[220]\tvalidation_0-mlogloss:0.76427\n",
      "[221]\tvalidation_0-mlogloss:0.76365\n",
      "[222]\tvalidation_0-mlogloss:0.76351\n",
      "[223]\tvalidation_0-mlogloss:0.76338\n",
      "[224]\tvalidation_0-mlogloss:0.76277\n",
      "[225]\tvalidation_0-mlogloss:0.76240\n",
      "[226]\tvalidation_0-mlogloss:0.76201\n",
      "[227]\tvalidation_0-mlogloss:0.76208\n",
      "[228]\tvalidation_0-mlogloss:0.76223\n",
      "[229]\tvalidation_0-mlogloss:0.76199\n",
      "[230]\tvalidation_0-mlogloss:0.76200\n",
      "[231]\tvalidation_0-mlogloss:0.76238\n",
      "[232]\tvalidation_0-mlogloss:0.76213\n",
      "[233]\tvalidation_0-mlogloss:0.76217\n",
      "[234]\tvalidation_0-mlogloss:0.76197\n",
      "[235]\tvalidation_0-mlogloss:0.76177\n",
      "[236]\tvalidation_0-mlogloss:0.76085\n",
      "[237]\tvalidation_0-mlogloss:0.76058\n",
      "[238]\tvalidation_0-mlogloss:0.75985\n",
      "[239]\tvalidation_0-mlogloss:0.75920\n",
      "[240]\tvalidation_0-mlogloss:0.75849\n",
      "[241]\tvalidation_0-mlogloss:0.75870\n",
      "[242]\tvalidation_0-mlogloss:0.75814\n",
      "[243]\tvalidation_0-mlogloss:0.75724\n",
      "[244]\tvalidation_0-mlogloss:0.75713\n",
      "[245]\tvalidation_0-mlogloss:0.75712\n",
      "[246]\tvalidation_0-mlogloss:0.75661\n",
      "[247]\tvalidation_0-mlogloss:0.75643\n",
      "[248]\tvalidation_0-mlogloss:0.75626\n",
      "[249]\tvalidation_0-mlogloss:0.75620\n",
      "[250]\tvalidation_0-mlogloss:0.75665\n",
      "[251]\tvalidation_0-mlogloss:0.75607\n",
      "[252]\tvalidation_0-mlogloss:0.75596\n",
      "[253]\tvalidation_0-mlogloss:0.75542\n",
      "[254]\tvalidation_0-mlogloss:0.75513\n",
      "[255]\tvalidation_0-mlogloss:0.75477\n",
      "[256]\tvalidation_0-mlogloss:0.75414\n",
      "[257]\tvalidation_0-mlogloss:0.75391\n",
      "[258]\tvalidation_0-mlogloss:0.75344\n",
      "[259]\tvalidation_0-mlogloss:0.75342\n",
      "[260]\tvalidation_0-mlogloss:0.75280\n",
      "[261]\tvalidation_0-mlogloss:0.75243\n",
      "[262]\tvalidation_0-mlogloss:0.75172\n",
      "[263]\tvalidation_0-mlogloss:0.75095\n",
      "[264]\tvalidation_0-mlogloss:0.75073\n",
      "[265]\tvalidation_0-mlogloss:0.75080\n",
      "[266]\tvalidation_0-mlogloss:0.75064\n",
      "[267]\tvalidation_0-mlogloss:0.75043\n",
      "[268]\tvalidation_0-mlogloss:0.75042\n",
      "[269]\tvalidation_0-mlogloss:0.75047\n",
      "[270]\tvalidation_0-mlogloss:0.75003\n",
      "[271]\tvalidation_0-mlogloss:0.74979\n",
      "[272]\tvalidation_0-mlogloss:0.75010\n",
      "[273]\tvalidation_0-mlogloss:0.74973\n",
      "[274]\tvalidation_0-mlogloss:0.74945\n",
      "[275]\tvalidation_0-mlogloss:0.74902\n",
      "[276]\tvalidation_0-mlogloss:0.74885\n",
      "[277]\tvalidation_0-mlogloss:0.74907\n",
      "[278]\tvalidation_0-mlogloss:0.74899\n",
      "[279]\tvalidation_0-mlogloss:0.74804\n",
      "[280]\tvalidation_0-mlogloss:0.74804\n",
      "[281]\tvalidation_0-mlogloss:0.74778\n",
      "[282]\tvalidation_0-mlogloss:0.74765\n",
      "[283]\tvalidation_0-mlogloss:0.74752\n",
      "[284]\tvalidation_0-mlogloss:0.74751\n",
      "[285]\tvalidation_0-mlogloss:0.74749\n",
      "[286]\tvalidation_0-mlogloss:0.74704\n",
      "[287]\tvalidation_0-mlogloss:0.74640\n",
      "[288]\tvalidation_0-mlogloss:0.74651\n",
      "[289]\tvalidation_0-mlogloss:0.74667\n",
      "[290]\tvalidation_0-mlogloss:0.74619\n",
      "[291]\tvalidation_0-mlogloss:0.74610\n",
      "[292]\tvalidation_0-mlogloss:0.74549\n",
      "[293]\tvalidation_0-mlogloss:0.74499\n",
      "[294]\tvalidation_0-mlogloss:0.74448\n",
      "[295]\tvalidation_0-mlogloss:0.74438\n",
      "[296]\tvalidation_0-mlogloss:0.74380\n",
      "[297]\tvalidation_0-mlogloss:0.74422\n",
      "[298]\tvalidation_0-mlogloss:0.74450\n",
      "[299]\tvalidation_0-mlogloss:0.74403\n",
      "[300]\tvalidation_0-mlogloss:0.74393\n",
      "[301]\tvalidation_0-mlogloss:0.74349\n",
      "[302]\tvalidation_0-mlogloss:0.74322\n",
      "[303]\tvalidation_0-mlogloss:0.74281\n",
      "[304]\tvalidation_0-mlogloss:0.74236\n",
      "[305]\tvalidation_0-mlogloss:0.74270\n",
      "[306]\tvalidation_0-mlogloss:0.74268\n",
      "[307]\tvalidation_0-mlogloss:0.74248\n",
      "[308]\tvalidation_0-mlogloss:0.74275\n",
      "[309]\tvalidation_0-mlogloss:0.74261\n",
      "[310]\tvalidation_0-mlogloss:0.74199\n",
      "[311]\tvalidation_0-mlogloss:0.74143\n",
      "[312]\tvalidation_0-mlogloss:0.74101\n",
      "[313]\tvalidation_0-mlogloss:0.74031\n",
      "[314]\tvalidation_0-mlogloss:0.73979\n",
      "[315]\tvalidation_0-mlogloss:0.73955\n",
      "[316]\tvalidation_0-mlogloss:0.73916\n",
      "[317]\tvalidation_0-mlogloss:0.73884\n",
      "[318]\tvalidation_0-mlogloss:0.73859\n",
      "[319]\tvalidation_0-mlogloss:0.73893\n",
      "[320]\tvalidation_0-mlogloss:0.73855\n",
      "[321]\tvalidation_0-mlogloss:0.73868\n",
      "[322]\tvalidation_0-mlogloss:0.73885\n",
      "[323]\tvalidation_0-mlogloss:0.73835\n",
      "[324]\tvalidation_0-mlogloss:0.73802\n",
      "[325]\tvalidation_0-mlogloss:0.73777\n",
      "[326]\tvalidation_0-mlogloss:0.73757\n",
      "[327]\tvalidation_0-mlogloss:0.73771\n",
      "[328]\tvalidation_0-mlogloss:0.73748\n",
      "[329]\tvalidation_0-mlogloss:0.73719\n",
      "[330]\tvalidation_0-mlogloss:0.73728\n",
      "[331]\tvalidation_0-mlogloss:0.73698\n",
      "[332]\tvalidation_0-mlogloss:0.73670\n",
      "[333]\tvalidation_0-mlogloss:0.73614\n",
      "[334]\tvalidation_0-mlogloss:0.73618\n",
      "[335]\tvalidation_0-mlogloss:0.73603\n",
      "[336]\tvalidation_0-mlogloss:0.73577\n",
      "[337]\tvalidation_0-mlogloss:0.73524\n",
      "[338]\tvalidation_0-mlogloss:0.73517\n",
      "[339]\tvalidation_0-mlogloss:0.73517\n",
      "[340]\tvalidation_0-mlogloss:0.73461\n",
      "[341]\tvalidation_0-mlogloss:0.73498\n",
      "[342]\tvalidation_0-mlogloss:0.73493\n",
      "[343]\tvalidation_0-mlogloss:0.73485\n",
      "[344]\tvalidation_0-mlogloss:0.73431\n",
      "[345]\tvalidation_0-mlogloss:0.73406\n",
      "[346]\tvalidation_0-mlogloss:0.73409\n",
      "[347]\tvalidation_0-mlogloss:0.73415\n",
      "[348]\tvalidation_0-mlogloss:0.73397\n",
      "[349]\tvalidation_0-mlogloss:0.73398\n",
      "[350]\tvalidation_0-mlogloss:0.73399\n",
      "[351]\tvalidation_0-mlogloss:0.73387\n",
      "[352]\tvalidation_0-mlogloss:0.73380\n",
      "[353]\tvalidation_0-mlogloss:0.73332\n",
      "[354]\tvalidation_0-mlogloss:0.73300\n",
      "[355]\tvalidation_0-mlogloss:0.73267\n",
      "[356]\tvalidation_0-mlogloss:0.73257\n",
      "[357]\tvalidation_0-mlogloss:0.73258\n",
      "[358]\tvalidation_0-mlogloss:0.73258\n",
      "[359]\tvalidation_0-mlogloss:0.73255\n",
      "[360]\tvalidation_0-mlogloss:0.73228\n",
      "[361]\tvalidation_0-mlogloss:0.73176\n",
      "[362]\tvalidation_0-mlogloss:0.73224\n",
      "[363]\tvalidation_0-mlogloss:0.73209\n",
      "[364]\tvalidation_0-mlogloss:0.73205\n",
      "[365]\tvalidation_0-mlogloss:0.73155\n",
      "[366]\tvalidation_0-mlogloss:0.73160\n",
      "[367]\tvalidation_0-mlogloss:0.73118\n",
      "[368]\tvalidation_0-mlogloss:0.73132\n",
      "[369]\tvalidation_0-mlogloss:0.73157\n",
      "[370]\tvalidation_0-mlogloss:0.73151\n",
      "[371]\tvalidation_0-mlogloss:0.73140\n",
      "[372]\tvalidation_0-mlogloss:0.73087\n",
      "[373]\tvalidation_0-mlogloss:0.73056\n",
      "[374]\tvalidation_0-mlogloss:0.73012\n",
      "[375]\tvalidation_0-mlogloss:0.72981\n",
      "[376]\tvalidation_0-mlogloss:0.72985\n",
      "[377]\tvalidation_0-mlogloss:0.72942\n",
      "[378]\tvalidation_0-mlogloss:0.72931\n",
      "[379]\tvalidation_0-mlogloss:0.72867\n",
      "[380]\tvalidation_0-mlogloss:0.72823\n",
      "[381]\tvalidation_0-mlogloss:0.72834\n",
      "[382]\tvalidation_0-mlogloss:0.72839\n",
      "[383]\tvalidation_0-mlogloss:0.72780\n",
      "[384]\tvalidation_0-mlogloss:0.72819\n",
      "[385]\tvalidation_0-mlogloss:0.72779\n",
      "[386]\tvalidation_0-mlogloss:0.72738\n",
      "[387]\tvalidation_0-mlogloss:0.72737\n",
      "[388]\tvalidation_0-mlogloss:0.72675\n",
      "[389]\tvalidation_0-mlogloss:0.72656\n",
      "[390]\tvalidation_0-mlogloss:0.72624\n",
      "최종 모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 셀 7: 최종 모델 학습\n",
    "# =============================================================================\n",
    "\n",
    "print(\"최종 모델 학습 시작...\")\n",
    "print(f\"학습 전 상태 | {check_gpu_memory()} | {check_system_memory()}\")\n",
    "\n",
    "# 메모리 정리\n",
    "clear_memory()\n",
    "\n",
    "# 최적 파라미터에 기본 파라미터 추가\n",
    "final_params = {\n",
    "    **best_params,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 3,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'n_jobs': PARALLEL_JOBS,\n",
    "    'verbosity': 1\n",
    "}\n",
    "\n",
    "# GPU 설정\n",
    "if USE_GPU:\n",
    "    final_params['tree_method'] = 'gpu_hist'\n",
    "    final_params['gpu_id'] = 0\n",
    "    final_params['predictor'] = 'gpu_predictor'\n",
    "    final_params['single_precision_histogram'] = True\n",
    "    print(\"GPU 가속 사용\")\n",
    "\n",
    "print(f\"최종 모델 파라미터:\")\n",
    "for key, value in final_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 샘플 가중치 계산\n",
    "sample_weights = np.array([class_weights[label] for label in y_train_val])\n",
    "print(f\"클래스 가중치 적용: {class_weights}\")\n",
    "print(f\"학습 준비 완료 | {check_gpu_memory()} | {check_system_memory()}\")\n",
    "\n",
    "# 최종 모델 학습\n",
    "print(f\"최종 모델 학습 진행...\")\n",
    "final_model = xgb.XGBClassifier(**final_params)\n",
    "\n",
    "final_model.fit(\n",
    "    X_train_val, y_train_val,\n",
    "    sample_weight=sample_weights,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"최종 모델 학습 완료!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16946b1",
   "metadata": {},
   "source": [
    "# 모델 Test & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "67c242cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "포괄적인 모델 평가 시작...\n",
      "============================================================\n",
      "성능 요약\n",
      "============================================================\n",
      "                  Accuracy   F1-Macro\n",
      "----------------------------------------\n",
      "Train               0.8471     0.8050\n",
      "Test                0.6436     0.5039\n",
      "CV (Best)                      0.5392\n",
      "\n",
      "과적합 분석:\n",
      "Train-Test 차이: 0.3010 (30.1%p)\n",
      "CV-Test 차이: 0.0352\n",
      "\n",
      "상세 분류 보고서 (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Strong_Sell       0.31      0.49      0.38      1580\n",
      "        Hold       0.83      0.69      0.75     10891\n",
      "  Strong_Buy       0.30      0.49      0.37      1596\n",
      "\n",
      "    accuracy                           0.64     14067\n",
      "   macro avg       0.48      0.56      0.50     14067\n",
      "weighted avg       0.71      0.64      0.67     14067\n",
      "\n",
      "혼동행렬:\n",
      "             Sell   Hold    Buy\n",
      "Strong_Sell   782   746    52\n",
      "Hold        1655  7490  1746\n",
      "Strong_Buy    57   757   782\n",
      "\n",
      "피쳐 중요도 Top 20:\n",
      "  19. Stoch_5_overbought            : 0.105636\n",
      "   2. Stoch_6_K_above_D             : 0.076456\n",
      "   1. Stoch_14_K_above_D            : 0.055122\n",
      "   3. CCI_4_overbought              : 0.047547\n",
      "  11. Stoch_K_3                     : 0.046323\n",
      "   5. Stoch_1_K_above_D             : 0.043029\n",
      "   4. Formula3_Signal               : 0.041955\n",
      "  17. CCI_3                         : 0.038398\n",
      "  13. Momentum_Signal               : 0.037911\n",
      "  12. is_month_start                : 0.032790\n",
      "  15. Volatility_7d                 : 0.031454\n",
      "   6. Stoch_4_K_above_D             : 0.031359\n",
      "  24. SMI_oversold_50               : 0.029170\n",
      "   9. is_month_end                  : 0.029144\n",
      "  10. Stoch_3_K_above_D             : 0.028651\n",
      "  21. SMI_overbought_40             : 0.028144\n",
      "   8. high_volatility_regime        : 0.027169\n",
      "  22. SMI_oversold_40               : 0.026698\n",
      "   7. is_quarter_start              : 0.026443\n",
      "  18. dow_sin                       : 0.026198\n",
      "\n",
      "모델 및 결과 저장 완료: /workspace/AI모델/projects/coin/models/v01/crypto_xgboost\n",
      "저장된 파일들:\n",
      "  - crypto_xgboost_final_model.pkl (모델)\n",
      "  - required_features.txt (피쳐 순서)\n",
      "  - feature_importance.csv (피쳐 중요도)\n",
      "  - best_params.json (최적 파라미터)\n",
      "  - evaluation_results.json (평가 결과)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 셀 8: 모델 평가 및 저장\n",
    "# =============================================================================\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, classification_report, \n",
    "    confusion_matrix, roc_auc_score\n",
    ")\n",
    "\n",
    "def evaluate_model_comprehensive(model, X_train_val, X_test, y_train_val, y_test, cv_score):\n",
    "    \"\"\"포괄적인 모델 평가\"\"\"\n",
    "    print(\"포괄적인 모델 평가 시작...\")\n",
    "    \n",
    "    # 예측 수행\n",
    "    train_pred = model.predict(X_train_val)\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_pred_proba = model.predict_proba(X_train_val)\n",
    "    test_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Train 성능\n",
    "    train_f1 = f1_score(y_train_val, train_pred, average='macro')\n",
    "    train_accuracy = accuracy_score(y_train_val, train_pred)\n",
    "    \n",
    "    # Test 성능\n",
    "    test_f1 = f1_score(y_test, test_pred, average='macro')\n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    # 과적합 분석\n",
    "    overfitting_gap = train_f1 - test_f1\n",
    "    cv_test_gap = abs(cv_score - test_f1)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"성능 요약\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'':15s} {'Accuracy':>10s} {'F1-Macro':>10s}\")\n",
    "    print(\"-\"*40)\n",
    "    print(f\"{'Train':15s} {train_accuracy:10.4f} {train_f1:10.4f}\")\n",
    "    print(f\"{'Test':15s} {test_accuracy:10.4f} {test_f1:10.4f}\")\n",
    "    print(f\"{'CV (Best)':15s} {'':10s} {cv_score:10.4f}\")\n",
    "    \n",
    "    print(\"\\n과적합 분석:\")\n",
    "    print(f\"Train-Test 차이: {overfitting_gap:.4f} ({overfitting_gap*100:.1f}%p)\")\n",
    "    print(f\"CV-Test 차이: {cv_test_gap:.4f}\")\n",
    "    \n",
    "    # if overfitting_gap < 0.02:\n",
    "    #     print(\"과적합 수준: 낮음 (양호)\")\n",
    "    # elif overfitting_gap < 0.05:\n",
    "    #     print(\"과적합 수준: 보통 (주의)\")\n",
    "    # else:\n",
    "    #     print(\"과적합 수준: 높음 (개선 필요)\")\n",
    "    \n",
    "    # 상세 분류 보고서\n",
    "    print(\"\\n상세 분류 보고서 (Test Set):\")\n",
    "    label_names = ['Strong_Sell', 'Hold', 'Strong_Buy']\n",
    "    print(classification_report(y_test, test_pred, target_names=label_names))\n",
    "    \n",
    "    # 혼동행렬\n",
    "    cm = confusion_matrix(y_test, test_pred)\n",
    "    print(\"혼동행렬:\")\n",
    "    print(f\"{'':10s} {'Sell':>6s} {'Hold':>6s} {'Buy':>6s}\")\n",
    "    for i, label in enumerate(label_names):\n",
    "        print(f\"{label:10s}\", end=\"\")\n",
    "        for j in range(3):\n",
    "            print(f\"{cm[i,j]:6d}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    return {\n",
    "        'train_f1': train_f1,\n",
    "        'test_f1': test_f1,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'cv_score': cv_score,\n",
    "        'overfitting_gap': overfitting_gap,\n",
    "        'cv_test_gap': cv_test_gap,\n",
    "        'confusion_matrix': cm,\n",
    "        'test_predictions': test_pred,\n",
    "        'test_probabilities': test_pred_proba\n",
    "    }\n",
    "\n",
    "# 평가 실행\n",
    "evaluation_results = evaluate_model_comprehensive(\n",
    "    final_model, X_train_val, X_test, y_train_val, y_test, best_cv_score\n",
    ")\n",
    "\n",
    "# 피쳐 중요도 계산\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n피쳐 중요도 Top 20:\")\n",
    "for i, row in feature_importance.head(20).iterrows():\n",
    "    print(f\"  {i+1:2d}. {row['feature']:30s}: {row['importance']:.6f}\")\n",
    "\n",
    "# 모델 및 결과 저장\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# 모델 저장\n",
    "model_path = os.path.join(output_dir, 'crypto_xgboost_final_model.pkl')\n",
    "joblib.dump(final_model, model_path)\n",
    "\n",
    "# 피쳐 리스트 저장 (모델이 요구하는 피쳐 순서)\n",
    "with open(os.path.join(output_dir, 'required_features.txt'), 'w') as f:\n",
    "    for feature in feature_columns:\n",
    "        f.write(f\"{feature}\\n\")\n",
    "\n",
    "# 피쳐 중요도 저장\n",
    "feature_importance.to_csv(os.path.join(output_dir, 'feature_importance.csv'), index=False)\n",
    "\n",
    "# 최적 파라미터 저장\n",
    "with open(os.path.join(output_dir, 'best_params.json'), 'w') as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "\n",
    "# 평가 결과 저장\n",
    "label_names = ['Strong_Sell', 'Hold', 'Strong_Buy']\n",
    "final_evaluation_results = {\n",
    "    'performance': {\n",
    "        'train_f1': evaluation_results['train_f1'],\n",
    "        'test_f1': evaluation_results['test_f1'],\n",
    "        'train_accuracy': evaluation_results['train_accuracy'],\n",
    "        'test_accuracy': evaluation_results['test_accuracy'],\n",
    "        'cv_score': evaluation_results['cv_score'],\n",
    "        'overfitting_gap': evaluation_results['overfitting_gap']\n",
    "    },\n",
    "    'confusion_matrix': evaluation_results['confusion_matrix'].tolist(),\n",
    "    'classification_report': classification_report(y_test, evaluation_results['test_predictions'], \n",
    "                                                  target_names=label_names, output_dict=True),\n",
    "    'feature_count': len(feature_columns),\n",
    "    'data_shape': {\n",
    "        'train_val': X_train_val.shape,\n",
    "        'test': X_test.shape\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, 'evaluation_results.json'), 'w') as f:\n",
    "    json.dump(final_evaluation_results, f, indent=2)\n",
    "\n",
    "print(f\"\\n모델 및 결과 저장 완료: {output_dir}\")\n",
    "print(f\"저장된 파일들:\")\n",
    "print(f\"  - crypto_xgboost_final_model.pkl (모델)\")\n",
    "print(f\"  - required_features.txt (피쳐 순서)\")\n",
    "print(f\"  - feature_importance.csv (피쳐 중요도)\")\n",
    "print(f\"  - best_params.json (최적 파라미터)\")\n",
    "print(f\"  - evaluation_results.json (평가 결과)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a645719",
   "metadata": {},
   "source": [
    "# 과적합 및 피처성능분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a6ecb192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🚀 종합적인 모델 진단 시작\n",
      "============================================================\n",
      "\n",
      "[1. 데이터 누수 및 시간적 순서 검증]\n",
      "----------------------------------------\n",
      "  ✅ Future 관련 피처 없음 (데이터 누수 방지 양호)\n",
      "  ⚠️ 경고: Train/Test 시간 중첩 발견! (Train Max: 2025-08-15 00:00:00, Test Min: 2024-02-16 00:00:00)\n",
      "\n",
      "[2. 과적합 분석]\n",
      "----------------------------------------\n",
      "  - Train/Test F1-Score 차이: 0.3010\n",
      "\n",
      "[3. 클래스 불균형 및 가중치 효과성 분석]\n",
      "----------------------------------------\n",
      "  - 클래스 균형도: 0.166 (1.0에 가까울수록 균형)\n",
      "  - 실제 vs 예측 분포 비교:\n",
      "    - Sell : 실제 11.2% vs 예측 17.7%\n",
      "    - Hold : 실제 77.4% vs 예측 63.9%\n",
      "    - Buy  : 실제 11.3% vs 예측 18.3%\n",
      "  - ✅ 평가: 클래스 가중치가 효과적으로 작동하여 Naive 모델 대비 성능이 개선되었습니다.\n",
      "\n",
      "[4. 피쳐 중요도 및 다중공선성 분석]\n",
      "----------------------------------------\n",
      "  - 중요도 0인 피쳐 수: 0개\n",
      "  - ✅ 평가: 주요 피쳐 간 높은 다중공선성 문제는 발견되지 않았습니다.\n",
      "\n",
      "[5. Future_Label과의 상관관계 분석]\n",
      "----------------------------------------\n",
      "  - Future_Label과 상관관계가 높은 상위 15개 피쳐:\n",
      "     1. Stoch_K_3                     : 0.3515\n",
      "     2. CCI_3                         : 0.3270\n",
      "     3. Stoch_14_K_above_D            : 0.2809\n",
      "     4. Stoch_6_K_above_D             : 0.2477\n",
      "     5. Stoch_5_overbought            : 0.2450\n",
      "     6. Stoch_4_K_above_D             : 0.2247\n",
      "     7. CCI_4_overbought              : 0.2187\n",
      "     8. Formula3_Signal               : 0.2130\n",
      "     9. Stoch_3_K_above_D             : 0.2087\n",
      "    10. Stoch_1_K_above_D             : 0.1711\n",
      "    11. Momentum_Signal               : 0.1588\n",
      "    12. SMI_signal                    : 0.0867\n",
      "    13. SMI_oversold_50               : 0.0663\n",
      "    14. SMI_overbought_50             : 0.0647\n",
      "    15. SMI_overbought_40             : 0.0645\n",
      "    16. SMI_oversold_40               : 0.0620\n",
      "    17. RSI_7_bullish_divergence      : 0.0210\n",
      "    18. RSI_7_bearish_divergence      : 0.0152\n",
      "    19. is_month_end                  : 0.0142\n",
      "    20. RSI_14_bearish_divergence     : 0.0142\n",
      "    21. RSI_14_bullish_divergence     : 0.0133\n",
      "    22. is_month_start                : 0.0132\n",
      "    23. Volatility_7d                 : 0.0109\n",
      "    24. is_quarter_start              : 0.0102\n",
      "    25. high_volatility_regime        : 0.0100\n",
      "    26. day_of_week                   : 0.0061\n",
      "    27. dow_sin                       : 0.0048\n",
      "    28. month_sin                     : 0.0016\n",
      "\n",
      "  - ⚠️ Future_Label과 상관관계가 매우 낮은 피쳐 (3개):\n",
      "    💡 제거 후보: ['day_of_week', 'dow_sin', 'month_sin']\n",
      "\n",
      "[6. 다중공선성 Top 30 상세 분석]\n",
      "----------------------------------------\n",
      "  - 상위 30개 피쳐 중 높은 상관관계(>0.7) 쌍: 9개\n",
      "  - Top 10 다중공선성 쌍:\n",
      "    SMI_overbought_40         ↔ SMI_overbought_50        : 0.8271\n",
      "    SMI_oversold_50           ↔ SMI_oversold_40          : 0.8095\n",
      "    Stoch_4_K_above_D         ↔ Stoch_3_K_above_D        : 0.8029\n",
      "    Stoch_K_3                 ↔ CCI_3                    : 0.7988\n",
      "    Stoch_6_K_above_D         ↔ Stoch_4_K_above_D        : 0.7538\n",
      "    dow_sin                   ↔ day_of_week              : 0.7343\n",
      "    Stoch_6_K_above_D         ↔ Stoch_14_K_above_D       : 0.7332\n",
      "    SMI_overbought_40         ↔ SMI_signal               : 0.7140\n",
      "    SMI_oversold_40           ↔ SMI_signal               : 0.7082\n",
      "\n",
      "  - 💡 다중공선성 제거 후보 (다른 피쳐와 높은 상관관계가 많은 순):\n",
      "    • SMI_overbought_40: 2개 피쳐와 높은 상관관계\n",
      "    • SMI_oversold_40: 2개 피쳐와 높은 상관관계\n",
      "    • Stoch_4_K_above_D: 2개 피쳐와 높은 상관관계\n",
      "    • Stoch_6_K_above_D: 2개 피쳐와 높은 상관관계\n",
      "    • SMI_signal: 2개 피쳐와 높은 상관관계\n",
      "  - 상위 30개 피쳐 간 평균 상관관계: 0.1098\n",
      "\n",
      "============================================================\n",
      "✅ 모델 진단 완료!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 셀 9: 종합적인 모델 진단 및 개선 방안 제시 (개선된 버전)\n",
    "# =============================================================================\n",
    "\n",
    "def run_model_diagnostics(evaluation_results, feature_importance, X_train_val, y_train_val, y_test, feature_columns, data_dir):\n",
    "    \"\"\"\n",
    "    모델 성능에 대한 종합적인 진단을 수행하고 개선 방안을 제시합니다.\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"🚀 종합적인 모델 진단 시작\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 1. 데이터 누수 및 시간적 순서 검증\n",
    "    print(\"\\n[1. 데이터 누수 및 시간적 순서 검증]\")\n",
    "    print(\"-\"*40)\n",
    "    future_leaks = [col for col in feature_columns if 'Future' in col and col != 'Future_Label']\n",
    "    if future_leaks:\n",
    "        print(f\"  ⚠️ 경고: Future 관련 피처가 포함됨 (누수 의심): {future_leaks}\")\n",
    "    else:\n",
    "        print(\"  ✅ Future 관련 피처 없음 (데이터 누수 방지 양호)\")\n",
    "\n",
    "    train_df = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(data_dir, 'test_data.csv'))\n",
    "    if 'Date' in train_df.columns and 'Date' in test_df.columns:\n",
    "        train_max_date = pd.to_datetime(train_df['Date']).max()\n",
    "        test_min_date = pd.to_datetime(test_df['Date']).min()\n",
    "        if test_min_date <= train_max_date:\n",
    "            print(f\"  ⚠️ 경고: Train/Test 시간 중첩 발견! (Train Max: {train_max_date}, Test Min: {test_min_date})\")\n",
    "        else:\n",
    "            print(f\"  ✅ 시간적 분할 올바름 (Train: ~{train_max_date.date()}, Test: {test_min_date.date()}~)\")\n",
    "\n",
    "    # 2. 과적합 분석\n",
    "    print(\"\\n[2. 과적합 분석]\")\n",
    "    print(\"-\"*40)\n",
    "    overfitting_gap = evaluation_results.get('overfitting_gap', 0)\n",
    "    print(f\"  - Train/Test F1-Score 차이: {overfitting_gap:.4f}\")\n",
    "    # if overfitting_gap > 0.05:\n",
    "    #     print(\"  - ⚠️ 평가: 과적합 가능성이 높습니다. 정규화 파라미터(alpha, lambda)를 높이거나, max_depth를 줄여보세요.\")\n",
    "    # else:\n",
    "    #     print(\"  - ✅ 평가: 과적합 수준이 안정적입니다.\")\n",
    "\n",
    "    # 3. 클래스 불균형 및 가중치 효과성 분석\n",
    "    print(\"\\n[3. 클래스 불균형 및 가중치 효과성 분석]\")\n",
    "    print(\"-\"*40)\n",
    "    class_ratio = y_train_val.value_counts().min() / y_train_val.value_counts().max()\n",
    "    print(f\"  - 클래스 균형도: {class_ratio:.3f} (1.0에 가까울수록 균형)\")\n",
    "\n",
    "    actual_dist = y_test.value_counts(normalize=True).sort_index() * 100\n",
    "    pred_dist = pd.Series(evaluation_results['test_predictions']).value_counts(normalize=True).sort_index() * 100\n",
    "    print(\"  - 실제 vs 예측 분포 비교:\")\n",
    "    for label, name in {0: 'Sell', 1: 'Hold', 2: 'Buy'}.items():\n",
    "        print(f\"    - {name:5s}: 실제 {actual_dist.get(label, 0):.1f}% vs 예측 {pred_dist.get(label, 0):.1f}%\")\n",
    "\n",
    "    naive_f1 = f1_score(y_test, np.ones_like(y_test), average='macro')\n",
    "    actual_f1 = evaluation_results['test_f1']\n",
    "    if actual_f1 - naive_f1 < 0.05:\n",
    "         print(\"  - ⚠️ 평가: 모델이 Hold로만 예측하는 Naive 모델 대비 성능 향상이 미미합니다. 클래스 가중치나 샘플링 기법(SMOTE 등)을 재검토하세요.\")\n",
    "    else:\n",
    "         print(\"  - ✅ 평가: 클래스 가중치가 효과적으로 작동하여 Naive 모델 대비 성능이 개선되었습니다.\")\n",
    "\n",
    "    # 4. 피쳐 중요도 및 다중공선성 분석\n",
    "    print(\"\\n[4. 피쳐 중요도 및 다중공선성 분석]\")\n",
    "    print(\"-\"*40)\n",
    "    zero_importance_count = (feature_importance['importance'] == 0).sum()\n",
    "    print(f\"  - 중요도 0인 피쳐 수: {zero_importance_count}개\")\n",
    "    if zero_importance_count > 0:\n",
    "        print(\"  - 💡 제안: 중요도가 0인 피쳐는 모델 성능에 기여하지 않으므로 제거를 고려해 볼 수 있습니다.\")\n",
    "\n",
    "    top_features = feature_importance.head(30)['feature'].tolist()\n",
    "    corr_matrix = X_train_val[top_features].corr().abs()\n",
    "    high_corr_pairs = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)).stack().reset_index()\n",
    "    high_corr_pairs.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
    "    high_corr_pairs = high_corr_pairs[high_corr_pairs['Correlation'] > 0.9]\n",
    "    if not high_corr_pairs.empty:\n",
    "        print(f\"  - ⚠️ 경고: 상위 피쳐 간 높은 상관관계({len(high_corr_pairs)}쌍)가 발견되었습니다. 다중공선성 문제가 있을 수 있습니다.\")\n",
    "        print(high_corr_pairs.head())\n",
    "    else:\n",
    "        print(\"  - ✅ 평가: 주요 피쳐 간 높은 다중공선성 문제는 발견되지 않았습니다.\")\n",
    "\n",
    "    # 5. Future_Label과의 상관관계 분석 (새로 추가)\n",
    "    print(\"\\n[5. Future_Label과의 상관관계 분석]\")\n",
    "    print(\"-\"*40)\n",
    "    try:\n",
    "        # 전체 데이터에서 Future_Label과의 상관관계 계산\n",
    "        full_train_df = pd.concat([\n",
    "            pd.DataFrame(X_train_val, columns=feature_columns),\n",
    "            pd.DataFrame({'Future_Label': y_train_val})\n",
    "        ], axis=1)\n",
    "        \n",
    "        # Future_Label과 각 피쳐 간의 상관관계 계산\n",
    "        target_correlations = full_train_df[feature_columns].corrwith(full_train_df['Future_Label']).abs()\n",
    "        target_correlations = target_correlations.dropna().sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"  - Future_Label과 상관관계가 높은 상위 15개 피쳐:\")\n",
    "        for i, (feature, corr) in enumerate(target_correlations.head(30).items(), 1):\n",
    "            print(f\"    {i:2d}. {feature:<30}: {corr:.4f}\")\n",
    "        \n",
    "        # 상관관계가 매우 낮은 피쳐들\n",
    "        low_corr_features = target_correlations[target_correlations < 0.01]\n",
    "        if len(low_corr_features) > 0:\n",
    "            print(f\"\\n  - ⚠️ Future_Label과 상관관계가 매우 낮은 피쳐 ({len(low_corr_features)}개):\")\n",
    "            print(f\"    💡 제거 후보: {list(low_corr_features.head(10).index)}\")\n",
    "        else:\n",
    "            print(\"  - ✅ 모든 피쳐가 Future_Label과 적절한 상관관계를 보입니다.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  - ❌ 상관관계 분석 중 오류: {e}\")\n",
    "\n",
    "    # 6. 다중공선성 Top 30 상세 분석 (새로 추가)\n",
    "    print(\"\\n[6. 다중공선성 Top 30 상세 분석]\")\n",
    "    print(\"-\"*40)\n",
    "    try:\n",
    "        # 상위 30개 피쳐 간 상관관계 매트릭스\n",
    "        top_30_features = feature_importance.head(30)['feature'].tolist()\n",
    "        corr_matrix_30 = X_train_val[top_30_features].corr().abs()\n",
    "        \n",
    "        # 상관관계가 높은 모든 쌍 찾기 (0.7 이상)\n",
    "        high_corr_pairs_detailed = []\n",
    "        for i in range(len(corr_matrix_30.columns)):\n",
    "            for j in range(i+1, len(corr_matrix_30.columns)):\n",
    "                corr_val = corr_matrix_30.iloc[i, j]\n",
    "                if corr_val > 0.7:  # 0.7 이상 상관관계\n",
    "                    high_corr_pairs_detailed.append({\n",
    "                        'Feature_1': corr_matrix_30.columns[i],\n",
    "                        'Feature_2': corr_matrix_30.columns[j],\n",
    "                        'Correlation': corr_val\n",
    "                    })\n",
    "        \n",
    "        if high_corr_pairs_detailed:\n",
    "            high_corr_df = pd.DataFrame(high_corr_pairs_detailed).sort_values('Correlation', ascending=False)\n",
    "            print(f\"  - 상위 30개 피쳐 중 높은 상관관계(>0.7) 쌍: {len(high_corr_df)}개\")\n",
    "            print(\"  - Top 10 다중공선성 쌍:\")\n",
    "            for i, row in high_corr_df.head(10).iterrows():\n",
    "                print(f\"    {row['Feature_1']:<25} ↔ {row['Feature_2']:<25}: {row['Correlation']:.4f}\")\n",
    "            \n",
    "            # 제거 후보 추천\n",
    "            feature_corr_count = {}\n",
    "            for _, row in high_corr_df.iterrows():\n",
    "                feature_corr_count[row['Feature_1']] = feature_corr_count.get(row['Feature_1'], 0) + 1\n",
    "                feature_corr_count[row['Feature_2']] = feature_corr_count.get(row['Feature_2'], 0) + 1\n",
    "            \n",
    "            if feature_corr_count:\n",
    "                most_correlated = sorted(feature_corr_count.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "                print(f\"\\n  - 💡 다중공선성 제거 후보 (다른 피쳐와 높은 상관관계가 많은 순):\")\n",
    "                for feature, count in most_correlated:\n",
    "                    print(f\"    • {feature}: {count}개 피쳐와 높은 상관관계\")\n",
    "        else:\n",
    "            print(\"  - ✅ 상위 30개 피쳐 간 높은 다중공선성(>0.7) 문제 없음\")\n",
    "            \n",
    "        # 평균 상관관계 계산\n",
    "        upper_triangle = corr_matrix_30.where(np.triu(np.ones(corr_matrix_30.shape), k=1).astype(bool))\n",
    "        avg_correlation = upper_triangle.stack().mean()\n",
    "        print(f\"  - 상위 30개 피쳐 간 평균 상관관계: {avg_correlation:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  - ❌ 다중공선성 분석 중 오류: {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✅ 모델 진단 완료!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# --- 진단 실행 ---\n",
    "# 이전에 계산된 evaluation_results와 feature_importance 변수가 필요합니다.\n",
    "run_model_diagnostics(\n",
    "    evaluation_results=evaluation_results,\n",
    "    feature_importance=feature_importance,\n",
    "    X_train_val=X_train_val,\n",
    "    y_train_val=y_train_val,\n",
    "    y_test=y_test,\n",
    "    feature_columns=feature_columns,\n",
    "    data_dir=data_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15dc522",
   "metadata": {},
   "source": [
    "# 백테스팅용 예측 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "398e80d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Test Set 백테스팅: 15% Test 데이터로 예측\n",
      "============================================================\n",
      "모델 및 피처 정보 로드 중...\n",
      "✅ 모델 로드 완료\n",
      "✅ 피처 컬럼 로드 완료: 28개\n",
      "\n",
      "🚀 Test Set 데이터 로드 중...\n",
      "✅ Test 데이터 로드 완료: (14067, 60)\n",
      "📅 기간: 전체 데이터의 마지막 15% (85~100%)\n",
      "🎯 종목 수: 50\n",
      "📋 종목 리스트: ['AAVE' 'ADA' 'AETHWETH' 'ALGO' 'AVAX' 'BCH' 'BGB' 'BNB' 'BTCB' 'BTC'\n",
      " 'CBBTC32994' 'CRO' 'DAI' 'DOGE' 'DOT' 'ENA' 'ETH' 'HBAR' 'HYPE32196'\n",
      " 'JITOSOL' 'LEO' 'LINK' 'LTC' 'MNT27075' 'NEAR' 'OKB' 'PEPE24478' 'SEI'\n",
      " 'SHIB' 'SOL' 'STETH' 'SUI20947' 'SUSDE' 'TAO22974' 'TON11419' 'TRX'\n",
      " 'UNI7083' 'USDC' 'USDE29470' 'USDS33039' 'USDT' 'WBETH' 'WBTC' 'WEETH'\n",
      " 'WETH' 'WSTETH' 'WTRX' 'XLM' 'XMR' 'XRP']\n",
      "📆 데이터 기간: 2024-02-16 ~ 2025-09-26\n",
      "\n",
      "🔍 데이터 분리 검증:\n",
      "❌ 시간적 중복 발견!\n",
      "   훈련+검증 종료: 2025-09-05\n",
      "   테스트 시작: 2024-02-16\n",
      "   ⚠️ 데이터 분할에 문제가 있을 수 있습니다!\n",
      "\n",
      "🤖 Test Set으로 예측 실행 중...\n",
      "🔧 테스트용 피처 데이터: (14067, 28)\n",
      "🎉 예측 완료!\n",
      "📊 예측 결과 분포:\n",
      "  0 (Sell): 2,494개 (17.7%)\n",
      "  1 (Hold): 8,993개 (63.9%)\n",
      "  2 (Buy): 2,580개 (18.3%)\n",
      "\n",
      "📝 예측 결과 추가 중...\n",
      "✅ 예측 결과가 추가된 데이터: (14067, 65)\n",
      "\n",
      "📈 Test Set 성능 검증:\n",
      "  🎯 정확도: 0.6436\n",
      "  📊 F1 Score: 0.5039\n",
      "  📝 유효 샘플: 14,067개\n",
      "\n",
      "📊 실제 vs 예측 라벨 분포:\n",
      "  Sell: 실제 11.2% vs 예측 17.7%\n",
      "  Hold: 실제 77.4% vs 예측 63.9%\n",
      "  Buy: 실제 11.3% vs 예측 18.3%\n",
      "\n",
      "📋 상세 분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Sell     0.3136    0.4949    0.3839      1580\n",
      "        Hold     0.8329    0.6877    0.7534     10891\n",
      "         Buy     0.3031    0.4900    0.3745      1596\n",
      "\n",
      "    accuracy                         0.6436     14067\n",
      "   macro avg     0.4832    0.5575    0.5039     14067\n",
      "weighted avg     0.7144    0.6436    0.6689     14067\n",
      "\n",
      "\n",
      "💾 백테스팅 결과 저장 중...\n",
      "✅ 예측이 포함된 테스트 데이터: /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/test_data_with_predictions.csv\n",
      "📊 백테스팅 핵심 데이터: (14067, 13)\n",
      "🔍 포함된 컬럼: ['Date', 'Symbol', 'Open', 'High', 'Low', 'Close', 'Volume', 'Predicted_Label', 'Predicted_Action', 'Pred_Prob_Sell', 'Pred_Prob_Hold', 'Pred_Prob_Buy', 'Future_Label']\n",
      "📝 샘플 데이터:\n",
      "        Date Symbol        Open        High         Low       Close  \\\n",
      "0 2024-12-27   AAVE  337.295990  350.418304  320.558319  323.264801   \n",
      "1 2024-12-28   AAVE  323.285919  360.378082  319.681488  353.539520   \n",
      "2 2024-12-29   AAVE  353.560852  354.098541  326.376953  332.002838   \n",
      "3 2024-12-30   AAVE  332.002441  343.250427  318.931915  321.680542   \n",
      "4 2024-12-31   AAVE  321.700684  326.832581  307.294861  308.641388   \n",
      "\n",
      "        Volume  Predicted_Label Predicted_Action  Pred_Prob_Sell  \\\n",
      "0  673675299.0                2              Buy        0.000398   \n",
      "1  571504291.0                0             Sell        0.724485   \n",
      "2  429476309.0                2              Buy        0.026547   \n",
      "3  691730195.0                2              Buy        0.000820   \n",
      "4  485558274.0                2              Buy        0.000412   \n",
      "\n",
      "   Pred_Prob_Hold  Pred_Prob_Buy  Future_Label  \n",
      "0        0.089430       0.910172           2.0  \n",
      "1        0.268239       0.007276           0.0  \n",
      "2        0.313069       0.660384           1.0  \n",
      "3        0.465700       0.533480           1.0  \n",
      "4        0.020843       0.978745           2.0  \n",
      "✅ 백테스팅 핵심 데이터: /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/test_backtest_essential.csv\n",
      "\n",
      "📁 종목별 백테스팅 데이터 분리 저장...\n",
      "  📄 AAVE: 274개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/AAVE_pure_backtest.csv\n",
      "  📄 ADA: 432개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/ADA_pure_backtest.csv\n",
      "  📄 AETHWETH: 21개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/AETHWETH_pure_backtest.csv\n",
      "  📄 ALGO: 344개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/ALGO_pure_backtest.csv\n",
      "  📄 AVAX: 275개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/AVAX_pure_backtest.csv\n",
      "  📄 BCH: 432개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/BCH_pure_backtest.csv\n",
      "  📄 BGB: 229개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/BGB_pure_backtest.csv\n",
      "  📄 BNB: 432개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/BNB_pure_backtest.csv\n",
      "  📄 BTCB: 344개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/BTCB_pure_backtest.csv\n",
      "  📄 BTC: 589개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/BTC_pure_backtest.csv\n",
      "  📄 CBBTC32994: 57개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/CBBTC32994_pure_backtest.csv\n",
      "  📄 CRO: 372개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/CRO_pure_backtest.csv\n",
      "  📄 DAI: 321개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/DAI_pure_backtest.csv\n",
      "  📄 DOGE: 432개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/DOGE_pure_backtest.csv\n",
      "  📄 DOT: 280개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/DOT_pure_backtest.csv\n",
      "  📄 ENA: 82개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/ENA_pure_backtest.csv\n",
      "  📄 ETH: 432개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/ETH_pure_backtest.csv\n",
      "  📄 HBAR: 331개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/HBAR_pure_backtest.csv\n",
      "  📄 HYPE32196: 46개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/HYPE32196_pure_backtest.csv\n",
      "  📄 JITOSOL: 159개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/JITOSOL_pure_backtest.csv\n",
      "  📄 LEO: 349개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/LEO_pure_backtest.csv\n",
      "  📄 LINK: 432개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/LINK_pure_backtest.csv\n",
      "  📄 LTC: 589개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/LTC_pure_backtest.csv\n",
      "  📄 MNT27075: 120개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/MNT27075_pure_backtest.csv\n",
      "  📄 NEAR: 272개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/NEAR_pure_backtest.csv\n",
      "  📄 OKB: 352개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/OKB_pure_backtest.csv\n",
      "  📄 PEPE24478: 135개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/PEPE24478_pure_backtest.csv\n",
      "  📄 SEI: 116개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/SEI_pure_backtest.csv\n",
      "  📄 SHIB: 277개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/SHIB_pure_backtest.csv\n",
      "  📄 SOL: 300개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/SOL_pure_backtest.csv\n",
      "  📄 STETH: 261개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/STETH_pure_backtest.csv\n",
      "  📄 SUI20947: 132개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/SUI20947_pure_backtest.csv\n",
      "  📄 SUSDE: 88개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/SUSDE_pure_backtest.csv\n",
      "  📄 TAO22974: 141개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/TAO22974_pure_backtest.csv\n",
      "  📄 TON11419: 224개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/TON11419_pure_backtest.csv\n",
      "  📄 TRX: 432개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/TRX_pure_backtest.csv\n",
      "  📄 UNI7083: 276개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/UNI7083_pure_backtest.csv\n",
      "  📄 USDC: 382개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/USDC_pure_backtest.csv\n",
      "  📄 USDE29470: 88개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/USDE29470_pure_backtest.csv\n",
      "  📄 USDS33039: 56개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/USDS33039_pure_backtest.csv\n",
      "  📄 USDT: 432개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/USDT_pure_backtest.csv\n",
      "  📄 WBETH: 133개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/WBETH_pure_backtest.csv\n",
      "  📄 WBTC: 365개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/WBTC_pure_backtest.csv\n",
      "  📄 WEETH: 99개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/WEETH_pure_backtest.csv\n",
      "  📄 WETH: 422개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/WETH_pure_backtest.csv\n",
      "  📄 WSTETH: 218개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/WSTETH_pure_backtest.csv\n",
      "  📄 WTRX: 196개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/WTRX_pure_backtest.csv\n",
      "  📄 XLM: 432개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/XLM_pure_backtest.csv\n",
      "  📄 XMR: 432개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/XMR_pure_backtest.csv\n",
      "  📄 XRP: 432개 → /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/XRP_pure_backtest.csv\n",
      "\n",
      "🎉 Test Set 백테스팅 완료!\n",
      "\n",
      "📋 생성된 파일들:\n",
      "  1. /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/test_data_with_predictions.csv (전체 테스트 데이터)\n",
      "  2. /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/test_backtest_essential.csv (백테스팅 핵심 데이터)\n",
      "  3. /workspace/AI모델/projects/coin/data/v01/crypto_xgboost/final_backtest_data/ (종목별 백테스팅 파일들)\n",
      "\n",
      "🎯 Test Set (15%) 데이터로 백테스팅 준비 완료!\n",
      "✅ 모델이 학습하지 않은 15% 데이터로 성능 측정 가능\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 셀 10: Test Set 백테스팅용 예측 데이터 생성 (70:15:15 분할)\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "# 경로 설정\n",
    "data_dir = \"/workspace/AI모델/projects/coin/data/v01/crypto_xgboost\"  # 전처리된 데이터 경로\n",
    "output_dir = \"/workspace/AI모델/projects/coin/models/v01/crypto_xgboost\"  # 모델 저장 경로\n",
    "\n",
    "print(\"🎯 Test Set 백테스팅: 15% Test 데이터로 예측\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. 모델 및 피처 로드\n",
    "# =============================================================================\n",
    "print(\"모델 및 피처 정보 로드 중...\")\n",
    "\n",
    "# 학습된 모델 로드\n",
    "model_path = os.path.join(output_dir, 'crypto_xgboost_final_model.pkl')\n",
    "final_model = joblib.load(model_path)\n",
    "print(f\"✅ 모델 로드 완료\")\n",
    "\n",
    "# 피처 컬럼 로드\n",
    "features_path = os.path.join(output_dir, 'required_features.txt')\n",
    "if not os.path.exists(features_path):\n",
    "    # training_features.txt로 시도\n",
    "    features_path = os.path.join(data_dir, 'training_features.txt')\n",
    "\n",
    "with open(features_path, 'r') as f:\n",
    "    feature_columns = [line.strip() for line in f.readlines()]\n",
    "print(f\"✅ 피처 컬럼 로드 완료: {len(feature_columns)}개\")\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Test Set 데이터 로드 (70:15:15 분할의 마지막 15%)\n",
    "# =============================================================================\n",
    "print(f\"\\n🚀 Test Set 데이터 로드 중...\")\n",
    "\n",
    "# Test 데이터 로드\n",
    "test_data_path = os.path.join(data_dir, 'test_data.csv')\n",
    "\n",
    "if not os.path.exists(test_data_path):\n",
    "    print(f\"❌ Test 데이터가 없습니다: {test_data_path}\")\n",
    "    print(f\"먼저 B00_00을 실행해주세요!\")\n",
    "    raise FileNotFoundError(f\"Test 데이터가 없습니다\")\n",
    "\n",
    "test_data_full = pd.read_csv(test_data_path)\n",
    "print(f\"✅ Test 데이터 로드 완료: {test_data_full.shape}\")\n",
    "print(f\"📅 기간: 전체 데이터의 마지막 15% (85~100%)\")\n",
    "print(f\"🎯 종목 수: {test_data_full['Symbol'].nunique()}\")\n",
    "print(f\"📋 종목 리스트: {test_data_full['Symbol'].unique()}\")\n",
    "\n",
    "# Date 컬럼 처리\n",
    "if 'Date' in test_data_full.columns:\n",
    "    test_data_full['Date'] = pd.to_datetime(test_data_full['Date'])\n",
    "    print(f\"📆 데이터 기간: {test_data_full['Date'].min().date()} ~ {test_data_full['Date'].max().date()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. 데이터 분리 검증 (중요!)\n",
    "# =============================================================================\n",
    "print(f\"\\n🔍 데이터 분리 검증:\")\n",
    "\n",
    "try:\n",
    "    # 훈련+검증 데이터 확인\n",
    "    train_data = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))\n",
    "    val_data = pd.read_csv(os.path.join(data_dir, 'val_data.csv')) if os.path.exists(os.path.join(data_dir, 'val_data.csv')) else pd.DataFrame()\n",
    "    \n",
    "    # 훈련+검증 데이터 결합\n",
    "    if len(val_data) > 0:\n",
    "        train_val_data = pd.concat([train_data, val_data], ignore_index=True)\n",
    "    else:\n",
    "        train_val_data = train_data\n",
    "        \n",
    "    train_val_data['Date'] = pd.to_datetime(train_val_data['Date'])\n",
    "    \n",
    "    train_val_max_date = train_val_data['Date'].max()\n",
    "    test_min_date = test_data_full['Date'].min()\n",
    "    \n",
    "    if test_min_date > train_val_max_date:\n",
    "        gap_days = (test_min_date - train_val_max_date).days\n",
    "        print(f\"✅ 완벽한 시간적 분리!\")\n",
    "        print(f\"   📚 훈련+검증 데이터 종료: {train_val_max_date.date()}\")\n",
    "        print(f\"   🎯 테스트 시작: {test_min_date.date()}\")\n",
    "        print(f\"   ⏰ 시간 간격: {gap_days}일\")\n",
    "    else:\n",
    "        print(f\"❌ 시간적 중복 발견!\")\n",
    "        print(f\"   훈련+검증 종료: {train_val_max_date.date()}\")\n",
    "        print(f\"   테스트 시작: {test_min_date.date()}\")\n",
    "        print(f\"   ⚠️ 데이터 분할에 문제가 있을 수 있습니다!\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 검증 중 오류: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Test Set으로 예측 실행\n",
    "# =============================================================================\n",
    "print(f\"\\n🤖 Test Set으로 예측 실행 중...\")\n",
    "\n",
    "# 누락된 피처 확인 및 처리\n",
    "missing_features = [col for col in feature_columns if col not in test_data_full.columns]\n",
    "if missing_features:\n",
    "    print(f\"⚠️ 누락된 피처: {missing_features}\")\n",
    "    for feature in missing_features:\n",
    "        test_data_full[feature] = 0\n",
    "        print(f\"   {feature} → 0으로 채움\")\n",
    "\n",
    "# 피처 데이터 준비\n",
    "X_test = test_data_full[feature_columns].fillna(0)\n",
    "X_test = X_test.replace([np.inf, -np.inf], 0)\n",
    "print(f\"🔧 테스트용 피처 데이터: {X_test.shape}\")\n",
    "\n",
    "# 모델로 예측 실행\n",
    "predictions = final_model.predict(X_test)\n",
    "prediction_probabilities = final_model.predict_proba(X_test)\n",
    "\n",
    "print(f\"🎉 예측 완료!\")\n",
    "print(f\"📊 예측 결과 분포:\")\n",
    "unique, counts = np.unique(predictions, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    label_name = {0: 'Sell', 1: 'Hold', 2: 'Buy'}[int(label)]\n",
    "    pct = count / len(predictions) * 100\n",
    "    print(f\"  {int(label)} ({label_name}): {count:,}개 ({pct:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# 5. 예측 결과를 테스트 데이터에 추가\n",
    "# =============================================================================\n",
    "print(f\"\\n📝 예측 결과 추가 중...\")\n",
    "\n",
    "# 예측 라벨 및 확률 추가\n",
    "test_data_full['Predicted_Label'] = predictions\n",
    "test_data_full['Pred_Prob_Sell'] = prediction_probabilities[:, 0]\n",
    "test_data_full['Pred_Prob_Hold'] = prediction_probabilities[:, 1]\n",
    "test_data_full['Pred_Prob_Buy'] = prediction_probabilities[:, 2]\n",
    "\n",
    "# 예측 액션을 텍스트로 변환\n",
    "label_map = {0: 'Sell', 1: 'Hold', 2: 'Buy'}\n",
    "test_data_full['Predicted_Action'] = test_data_full['Predicted_Label'].map(label_map)\n",
    "\n",
    "print(f\"✅ 예측 결과가 추가된 데이터: {test_data_full.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 6. 성능 검증 (실제 라벨과 비교)\n",
    "# =============================================================================\n",
    "if 'Future_Label' in test_data_full.columns:\n",
    "    print(f\"\\n📈 Test Set 성능 검증:\")\n",
    "    \n",
    "    actual_labels = test_data_full['Future_Label'].fillna(1).astype(int)  # NaN을 Hold로 처리\n",
    "    valid_mask = actual_labels.isin([0, 1, 2])\n",
    "    \n",
    "    if valid_mask.sum() > 0:\n",
    "        actual_valid = actual_labels[valid_mask]\n",
    "        pred_valid = predictions[valid_mask]\n",
    "        \n",
    "        test_accuracy = accuracy_score(actual_valid, pred_valid)\n",
    "        test_f1 = f1_score(actual_valid, pred_valid, average='macro')\n",
    "        \n",
    "        print(f\"  🎯 정확도: {test_accuracy:.4f}\")\n",
    "        print(f\"  📊 F1 Score: {test_f1:.4f}\")\n",
    "        print(f\"  📝 유효 샘플: {len(actual_valid):,}개\")\n",
    "        \n",
    "        # 실제 vs 예측 분포 비교\n",
    "        print(f\"\\n📊 실제 vs 예측 라벨 분포:\")\n",
    "        actual_dist = pd.Series(actual_valid).value_counts(normalize=True).sort_index() * 100\n",
    "        pred_dist = pd.Series(pred_valid).value_counts(normalize=True).sort_index() * 100\n",
    "        \n",
    "        for label, name in {0: 'Sell', 1: 'Hold', 2: 'Buy'}.items():\n",
    "            actual_pct = actual_dist.get(label, 0)\n",
    "            pred_pct = pred_dist.get(label, 0)\n",
    "            print(f\"  {name}: 실제 {actual_pct:.1f}% vs 예측 {pred_pct:.1f}%\")\n",
    "        \n",
    "        print(f\"\\n📋 상세 분류 보고서:\")\n",
    "        print(classification_report(actual_valid, pred_valid, \n",
    "                                   target_names=['Sell', 'Hold', 'Buy'], digits=4))\n",
    "    else:\n",
    "        print(f\"  ⚠️ 유효한 실제 라벨이 없습니다.\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ Future_Label이 없어 성능 검증을 건너뜁니다.\")\n",
    "\n",
    "# =============================================================================\n",
    "# 7. 결과 저장\n",
    "# =============================================================================\n",
    "print(f\"\\n💾 백테스팅 결과 저장 중...\")\n",
    "\n",
    "# 완전한 테스트 데이터 저장\n",
    "complete_test_path = os.path.join(data_dir, 'test_data_with_predictions.csv')\n",
    "test_data_full.to_csv(complete_test_path, index=False)\n",
    "print(f\"✅ 예측이 포함된 테스트 데이터: {complete_test_path}\")\n",
    "\n",
    "# 백테스팅용 핵심 데이터만 추출\n",
    "essential_columns = ['Date', 'Symbol', 'Close', 'Predicted_Label', \n",
    "                    'Predicted_Action', 'Pred_Prob_Sell', \n",
    "                    'Pred_Prob_Hold', 'Pred_Prob_Buy']\n",
    "\n",
    "# 원본 OHLCV 데이터도 포함 (백테스팅에 필요)\n",
    "backtest_columns = ['Date', 'Symbol', 'Open', 'High', 'Low', 'Close', 'Volume',\n",
    "                   'Predicted_Label', 'Predicted_Action', 'Pred_Prob_Sell', \n",
    "                   'Pred_Prob_Hold', 'Pred_Prob_Buy']\n",
    "\n",
    "# 컬럼 존재 여부 확인\n",
    "available_backtest = [col for col in backtest_columns if col in test_data_full.columns]\n",
    "if 'Future_Label' in test_data_full.columns:\n",
    "    available_backtest.append('Future_Label')  # 성능 검증용으로 포함\n",
    "\n",
    "backtest_essential = test_data_full[available_backtest].copy()\n",
    "\n",
    "# 시간순 정렬\n",
    "if 'Date' in backtest_essential.columns:\n",
    "    backtest_essential = backtest_essential.sort_values(['Symbol', 'Date']).reset_index(drop=True)\n",
    "\n",
    "print(f\"📊 백테스팅 핵심 데이터: {backtest_essential.shape}\")\n",
    "print(f\"🔍 포함된 컬럼: {list(backtest_essential.columns)}\")\n",
    "print(f\"📝 샘플 데이터:\")\n",
    "print(backtest_essential.head(5))\n",
    "\n",
    "# 백테스팅 핵심 데이터 저장\n",
    "essential_test_path = os.path.join(data_dir, 'test_backtest_essential.csv')\n",
    "backtest_essential.to_csv(essential_test_path, index=False)\n",
    "print(f\"✅ 백테스팅 핵심 데이터: {essential_test_path}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 8. 종목별 백테스팅 데이터 분리 저장\n",
    "# =============================================================================\n",
    "print(f\"\\n📁 종목별 백테스팅 데이터 분리 저장...\")\n",
    "\n",
    "final_backtest_dir = os.path.join(data_dir, 'final_backtest_data')\n",
    "os.makedirs(final_backtest_dir, exist_ok=True)\n",
    "\n",
    "for symbol in test_data_full['Symbol'].unique():\n",
    "    symbol_data = test_data_full[test_data_full['Symbol'] == symbol].copy()\n",
    "    if 'Date' in symbol_data.columns:\n",
    "        symbol_data = symbol_data.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # 백테스팅에 필요한 컬럼만 선택\n",
    "    symbol_backtest = symbol_data[available_backtest].copy()\n",
    "    \n",
    "    output_file = os.path.join(final_backtest_dir, f'{symbol}_pure_backtest.csv')\n",
    "    symbol_backtest.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"  📄 {symbol}: {len(symbol_backtest):,}개 → {output_file}\")\n",
    "\n",
    "print(f\"\\n🎉 Test Set 백테스팅 완료!\")\n",
    "print(f\"\\n📋 생성된 파일들:\")\n",
    "print(f\"  1. {complete_test_path} (전체 테스트 데이터)\")\n",
    "print(f\"  2. {essential_test_path} (백테스팅 핵심 데이터)\")\n",
    "print(f\"  3. {final_backtest_dir}/ (종목별 백테스팅 파일들)\")\n",
    "\n",
    "print(f\"\\n🎯 Test Set (15%) 데이터로 백테스팅 준비 완료!\")\n",
    "print(f\"✅ 모델이 학습하지 않은 15% 데이터로 성능 측정 가능\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151987ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
